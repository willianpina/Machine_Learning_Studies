{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modelagem de dados sequenciais usando redes neurais recorrentes</h1>\n",
    "\n",
    "<p align=center><img src=https://datascience.eu/wp-content/uploads/2020/05/image-513-1024x347.png></p>\n",
    "\n",
    "Tivemos oportunidade de focar em redes neurais convolucionais (*CNNs*), de forma a cobrir os blocos de construção das arquiteturas *CNN* e como implementar *CNNs* profundas no *TensorFlow*. Por fim, você aprendeu a usar *CNNs* para classificação de imagens.\n",
    "\n",
    "Aqui, exploraremos as redes neurais recorrentes (*RNNs*) e veremos sua aplicação na modelagem de dados sequenciais.\n",
    "\n",
    "### Apresentando dados sequenciais\n",
    "Vamos começar nossa discussão sobre *RNNs* observando a natureza dos dados sequenciais, que são mais comumente conhecidos como dados de sequência ou **sequências**. Vamos dar uma olhada nas propriedades únicas das sequências que as tornam diferentes de outros tipos de dados. Veremos então como podemos representar dados sequenciais e explorar as várias categorias de modelos para dados sequenciais, que são baseados na entrada e saída de um modelo. Isso nos ajudará a explorar a relação entre *RNNs* e sequências.\n",
    "\n",
    "### Modelagem de dados sequenciais - a ordem importa\n",
    "\n",
    "O que torna as sequências únicas, em comparação com outros tipos de dados, é que os elementos em uma sequência aparecem em uma determinada ordem e não são independentes uns dos outros. Algoritmos típicos de aprendizado de máquina para aprendizado supervisionado pressupõem que a entrada de dados é **independente e e distribuída de forma idêntica (IID)**, o que significa que os exemplos de treinamento são `mutuamente independentes` e têm a mesma distribuição subjacente.\n",
    "\n",
    "Nesse sentido, com base na suposição de independência mútua, a ordem em que os exemplos de treinamento são dados ao modelo é **irrelevante**. Por exemplo, se tivermos uma amostra composta por n exemplos de treinamento, $\\small x^{(1)}, x^{(2)},\\cdots, x^{(n)} $, a ordem em que usamos os dados para treinar nosso algoritmo de aprendizado de máquina não importa. Um exemplo desse cenário seria o conjunto de dados Iris, muito conhecido. No conjunto de dados Iris, cada flor foi medida independentemente e as medidas de uma flor não influenciam as medidas de outra flor.\n",
    "\n",
    "No entanto, essa suposição não é válida quando lidamos com sequências – por definição, **a ordem é importante**. Prever o valor de mercado de uma determinada ação seria um exemplo desse cenário. Por exemplo, suponha que temos uma amostra de n exemplos de treinamento, onde cada exemplo de treinamento representa o valor de mercado de uma determinada ação em um determinado dia. Se nossa tarefa é prever o valor do mercado de ações para os próximos três dias, faria sentido considerar os preços das ações anteriores em uma ordem de data para derivar tendências, em vez de utilizar esses exemplos de treinamento em uma ordem aleatória.\n",
    "\n",
    "> #### Dados sequenciais versus dados de séries temporais\n",
    "> Os dados de série temporal são um tipo especial de dados sequenciais, em que cada exemplo está associado a uma dimensão de tempo. Em dados de séries temporais, as amostras são coletadas em *timestamps* sucessivos e, portanto, a dimensão de tempo determina a ordem entre os pontos de dados. Por exemplo, preços de ações e registros de voz ou fala são dados de séries temporais.\n",
    ">\n",
    "> Por outro lado, nem todos os dados sequenciais têm a dimensão temporal, por exemplo, dados de texto ou sequências de DNA, onde os exemplos são ordenados, mas não se qualificam como dados de séries temporais. Como você verá, abordaremos alguns exemplos de Processamento de Linguagem Natural (NLP) e modelagem de texto que não são dados de série temporal, mas observe que as *RNNs* também podem ser usados para dados de série temporal.\n",
    "\n",
    "### Representando sequências\n",
    "\n",
    "Estabelecemos que a ordem entre os pontos de dados é importante em dados sequenciais, então precisamos encontrar uma maneira de aproveitar essas informações de pedido em um modelo de aprendizado de máquina. Ao longo das explicações, representaremos as sequências como $\\small \\left \\langle x^{(1)},x^{(2)},\\cdots, x^{(T)}  \\right \\rangle$ . Os índices sobrescritos indicam a ordem das instâncias e o comprimento da sequência é $\\small T$. Para um exemplo sensato de sequências, considere dados de séries temporais, onde cada ponto de exemplo, $\\small x^{(T)}$, pertence a um determinado tempo, $\\small t$. A figura a seguir mostra um exemplo de dados de série temporal em que os recursos de entrada ($\\small x$) e os rótulos de destino ($\\small y$) seguem naturalmente a ordem de acordo com seu eixo de tempo; portanto, ambos os `x` e `y` são sequências:\n",
    "\n",
    "![](imagens\\sequencias.PNG)\n",
    "\n",
    "Como já mencionamos, os modelos de rede neural padrão (*RN*) que abordamos até agora, como o *multilayer perceptron* (MLP) e as *CNNs* para dados de imagem, assumem que os exemplos de treinamento são independentes uns dos outros e, portanto, não incorporam **informação de ordenamento**. Podemos dizer que tais modelos não possuem **memória** de exemplos de treinamento vistos anteriormente. Por exemplo, as amostras são passadas pelas etapas de *feedforward* e *backpropagation* e os pesos são atualizados independentemente da ordem em que os exemplos de treinamento são processados. As *RNNs*, por outro lado, são projetadas para modelar sequências e são capazes de lembrar informações passadas e processar novos eventos de acordo, o que é uma clara vantagem ao trabalhar com dados de sequência.\n",
    "\n",
    "### As diferentes categorias de modelagem de sequência\n",
    "\n",
    "A modelagem de sequência tem muitas aplicações fascinantes, como tradução de idiomas (por exemplo, tradução de texto de inglês para alemão), legendas de imagens e geração de texto. No entanto, para escolher uma arquitetura e abordagem apropriadas, temos que entender e ser capazes de distinguir entre essas diferentes tarefas de modelagem de sequência. A figura a seguir, baseada nas explicações do excelente artigo The Unreasonable Effectiveness of Recurrent Neural Networks, de Andrej Karpathy (http://karpathy.github.io/2015/05/21/rnn-effectiveness/), resume a sequência mais comum tarefas de modelagem, que dependem das categorias de relacionamento de dados de entrada e saída:\n",
    "\n",
    "![](imagens\\modelagem_de_sequencia.PNG)\n",
    "\n",
    "Vamos discutir as diferentes categorias de relacionamento entre dados de entrada e saída, que foram descritas na figura anterior, com mais detalhes. Se nem os dados de entrada nem de saída representam sequências, então estamos lidando com dados padrão e podemos simplesmente usar um perceptron multicamada (ou outro modelo de classificação abordado anteriormente) para modelar esses dados. No entanto, se a entrada ou a saída for uma sequência, a tarefa de modelagem provavelmente se enquadra em uma destas categorias:\n",
    "* **Muitos para um**: Os dados de entrada são uma sequência, mas a saída é um vetor de tamanho fixo ou escalar, não uma sequência. Por exemplo, na análise de sentimentos, a entrada é baseada em texto (por exemplo, uma resenha de filme) e a saída é um rótulo de classe (por exemplo, um rótulo que indica se um revisor gostou do filme).\n",
    "\n",
    "* **Um para muitos**: Os dados de entrada estão no formato padrão e não em sequência, mas a saída é uma sequência. Um exemplo dessa categoria é a legendagem de imagens — a entrada é uma imagem e a saída é uma frase em inglês que resume o conteúdo dessa imagem.\n",
    "\n",
    "* **Muitos para muitos**: As matrizes de entrada e saída são sequências. Esta categoria pode ser dividida com base na sincronização da entrada e saída. Um exemplo de uma tarefa de modelagem sincronizada de muitos para muitos é a classificação de vídeo, onde cada quadro em um vídeo é rotulado. Um exemplo de uma tarefa de modelagem muitos-para-muitos *atrasada* seria traduzir uma linguagem para outra. Por exemplo, uma frase inteira em inglês deve ser lida e processada por uma máquina antes que sua tradução para o alemão seja produzida. \n",
    "\n",
    "Agora, depois de resumir as três grandes categorias de modelagem de sequência, podemos avançar para discutir a estrutura de uma RNN.\n",
    "\n",
    "### RNNs para modelagem de sequências \n",
    "Nesta seção, antes de começarmos a implementar *RNNs* no *TensorFlow*, discutiremos os principais conceitos de *RNNs*. Começaremos examinando a estrutura típica de uma *RNN*, que inclui um componente recursivo para modelar dados de sequência. Em seguida, examinaremos como as ativações dos neurônios são computadas em uma *RNN* típica. Isso criará um contexto para discutirmos os desafios comuns no treinamento de *RNNs* e, em seguida, discutiremos soluções para esses desafios, como *LSTM* e unidades recorrentes fechadas (*GRUs*).\n",
    "\n",
    "### Entendendo o mecanismo de loop *RNN*\n",
    "Vamos começar com a arquitetura de uma *RNN*. A figura a seguir mostra uma *RN* *feedforward* padrão e um *RNN* lado a lado para comparação:\n",
    "\n",
    "![](imagens\\mecanismo_loop_rnn.PNG)\n",
    "\n",
    "Ambas as redes têm apenas uma camada oculta. Nesta representação, as unidades não são exibidas, mas assumimos que a camada de entrada ($\\small x$), a camada oculta ($\\small h$) e a camada de saída ($\\small o$) são vetores que contêm muitas unidades.\n",
    "\n",
    "> ##### Determinando o tipo de saída de um RNN\n",
    "> Essa arquitetura RNN genérica pode corresponder às duas categorias de modelagem de sequência em que a entrada é uma sequência. Normalmente, uma camada recorrente pode retornar uma sequência como saída, $\\small \\left \\langle o^{(1)},o^{(2)},\\cdots, o^{(T)}  \\right \\rangle$, ou simplesmente retornar a última saída (em $\\small t = T$, ou seja, $\\small o^{(T)}$). Assim, pode ser muitos para muitos ou muitos para um se, por exemplo, usarmos apenas o último elemento, $\\small o^{(T)}$, como a saída final.\n",
    ">\n",
    "> Como você verá mais tarde, na *API TensorFlow Keras*, o comportamento de uma camada recorrente em relação ao retorno de uma sequência como saída ou simplesmente usar a última saída pode ser especificado definindo o argumento `return_sequences` como `True` ou `False`, respectivamente.\n",
    "\n",
    "Em uma rede *feedforward* padrão, as informações fluem da entrada para a camada oculta e, em seguida, da camada oculta para a camada de saída. Por outro lado, em uma *RNN*, a camada oculta recebe sua entrada tanto da camada de entrada da etapa de tempo atual quanto da camada oculta da etapa de tempo anterior.\n",
    "\n",
    "O fluxo de informações em etapas de tempo adjacentes na camada oculta permite que a rede tenha uma memória de eventos passados. Esse fluxo de informações geralmente é exibido como um *loop*, também conhecido como **recurrent edge** (borda recorrente) em notação de gráfico, que é como essa arquitetura *RNN* geral recebeu seu nome.\n",
    "\n",
    "Semelhante aos *perceptrons* multicamadas, as *RNN*s podem consistir em várias camadas ocultas. Observe que é uma convenção comum se referir às *RNNs* com uma camada oculta como uma *RNN* de camada única, que não deve ser confundido com as RNs de camada única sem uma camada oculta, como *Adaline* ou *regressão logística*. A figura a seguir ilustra uma *RNN* com uma camada oculta (superior) e uma *RNN* com duas camadas ocultas (inferior):\n",
    "\n",
    "![](imagens\\rnn_oculta.PNG)\n",
    "\n",
    "Para examinar a arquitetura das *RNNs* e o fluxo de informações, pode-se desdobrar uma representação compacta com uma aresta recorrente, que você pode ver na figura anterior.\n",
    "\n",
    "Como sabemos, cada unidade oculta em uma *RN* padrão recebe apenas uma entrada – a pré-ativação de rede associada à camada de entrada. Em contraste, cada unidade oculta em uma *RNN* recebe dois conjuntos distintos de entrada – a pré-ativação da camada de entrada e a ativação da mesma camada oculta da etapa de tempo anterior, $\\small t – 1$.\n",
    "\n",
    "Na primeira etapa de tempo, $\\small t = 0$, as unidades ocultas são inicializadas com zeros ou pequenos valores aleatórios. Então, em um passo de tempo em que $\\small t > 0$, as unidades ocultas recebem sua entrada do ponto de dados no momento atual, $\\small x^{(T)}$, e os valores anteriores das unidades ocultas em $\\small t – 1$, indicados como $\\small h^{(t-1)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma, no caso de uma RNN multicamada, podemos resumir o fluxo de informações da seguinte forma:\n",
    "* $\\small layer$ = 1: Aqui, a camada oculta é representada como $h_1^{(t)}$ e recebe sua entrada do ponto de dados, $x^{(t)}$, e os valores ocultos na mesma camada, mas no passo de tempo anterior, $h_1^{(t - 1)}$.\n",
    "* $\\small layer$ = 2: A segunda camada oculta, $h_2^{(t)}$ , recebe suas entradas das saídas da camada abaixo na etapa de tempo atual $(o_1^{(t)})$ e seus próprios valores ocultos da etapa de tempo anterior, $h_2^{(t-1)}$.\n",
    "\n",
    "Como, neste caso, cada camada recorrente deve receber uma sequência como entrada, todas as camadas recorrentes, exceto a última, devem retornar uma sequência como saída (ou seja, `return_sequences=True`). O comportamento da última camada recorrente depende do tipo de problema.\n",
    "\n",
    "### Computando ativações em uma *RNN*\n",
    "Agora que você entende a estrutura e o fluxo geral de informações em uma *RNN*, vamos ser mais específicos e calcular as ativações reais das camadas ocultas, bem como a camada de saída. Para simplificar, consideraremos apenas uma única camada oculta; no entanto, o mesmo conceito se aplica às *RNNs* multicamadas.\n",
    "\n",
    "Cada aresta direcionada (as conexões entre caixas) na representação de uma *RNN* que acabamos de ver está associada a uma matriz de pesos. Esses pesos não dependem do tempo, $\\small t$; portanto, eles são compartilhados ao longo do eixo do tempo. As diferentes matrizes de peso em uma *RNN* de camada única são as seguintes:\n",
    "* $\\small \\textbf{W}_{xh}$: A matriz de peso entre a entrada, $\\small x^{(t)}$, e a camada oculta, $\\small \\textbf{h}$\n",
    "* $\\small \\textbf{W}_{hh}$: A matriz de peso associada à aresta recorrente\n",
    "* $\\small \\textbf{W}_{ho}$: A matriz de peso entre a camada oculta e a camada de saída\n",
    "\n",
    "Essas matrizes de peso são representadas na figura a seguir:\n",
    "\n",
    "![](imagens\\matriz_pesos.PNG)\n",
    "\n",
    "Em certas implementações, você pode observar que as matrizes de peso, $\\small \\textbf{W}_{xh}$ e $\\small \\textbf{W}_{hh}$, são concatenadas a uma matriz combinada, $\\small \\textbf{W}_{h} = [\\textbf{W}_{xh}; \\textbf{W}_{hh}]$. Mais adiante, faremos uso dessa notação também.\n",
    "\n",
    "A computação das ativações é muito semelhante aos *perceptrons* multicamadas padrão e outros tipos de *RNs* *feedforward*. Para a camada oculta, a entrada líquida, $\\small \\textbf{z}_ h$ (pré-ativação), é calculada através de uma combinação linear, ou seja, calculamos a soma das multiplicações das matrizes de peso com os vetores correspondentes e somamos a unidade de polarização:\n",
    "$$\n",
    "\\small \\textbf{z}_h^{(t)} = \\text{W}_{xh} \\textbf{x}^{(t)} + \\textbf{W}_{hh}\\textbf{h}^{(t-1)} + \\textbf{b}_h\n",
    "$$\n",
    "\n",
    "Então, as ativações das unidades ocultas na etapa do tempo, $\\small t$, são calculadas da seguinte forma:\n",
    "\n",
    "$$\n",
    "\\textbf{h}^{(t)} = \\phi_h (\\textbf{z}_h^{(t)}) = \\phi_h (\\textbf{W}_{xh}\\textbf{x}^{(t)} +  \\textbf{W}_{hh}\\textbf{x}^{(t-1)} + \\textbf{b}_h)\n",
    "$$\n",
    " \n",
    "Aqui, $\\small \\textbf{b}_h$ é o vetor de polarização para as unidades ocultas e $\\phi_h(\\cdot)$ é a função de ativação da camada oculta.\n",
    "\n",
    "Caso você queira usar a matriz de peso concatenada, $\\small \\textbf{W}_h = [\\textbf{W}_{xh}; \\textbf{W}_{hh}]$, a fórmula para calcular as unidades ocultas mudará da seguinte forma:\n",
    "\n",
    "$$\n",
    "\\small \\textbf{h}^{(t)} = \\phi_h \\left ([\\textbf{W}_{xh}; \\textbf{W}_{hh}] \\begin{bmatrix}\n",
    "\\textbf{x}^{(t)}\\\\ \n",
    "\\textbf{h}^{t-1}\n",
    "\\end{bmatrix}       \n",
    "+ \\textbf{b}_h          \\right )\n",
    "$$\n",
    "\n",
    "Uma vez computadas as ativações das unidades ocultas no passo de tempo atual, serão computadas as ativações das unidades de saída, como segue:\n",
    "\n",
    "$$\n",
    "\\small \\textbf{o}^{(t)} = \\phi_0 (\\textbf{W}_{ho}\\textbf{h}^{(t)} + \\textbf{b}_0)\n",
    "$$\n",
    "\n",
    "Para ajudar a esclarecer ainda mais, a figura a seguir mostra o processo de cálculo dessas ativações com ambas as formulações:\n",
    "\n",
    "![](imagens\\matriz_sequencial.PNG)\n",
    "\n",
    "> ##### Treinando RNNs usando retropropagação ao longo do tempo (BPTT)\n",
    "> O algoritmo de aprendizado para RNNs foi introduzido em 1990: Backpropagation Through Time: What It Does and How to Do It (Paul Werbos, Proceedings of IEEE, 78(10): 1550-1560, 1990). A derivada dos gradientes pode ser um pouco complicada, mas a ideia básica é que a perda total, $\\small L$, é a soma de todas as funções de perda nos momentos $\\small t = 1$ a $\\small t = T$:\n",
    "\n",
    "$$\n",
    "L = \\sum^T_{t=1}L^{(t)}\n",
    "$$\n",
    "\n",
    "Como a perda no tempo $\\small t$ depende das unidades ocultas em todos os passos de tempo anteriores $\\small 1 : t$, o gradiente será calculado da seguinte forma:\n",
    "\n",
    "$$\n",
    "\\small \\dfrac{\\partial L^{(t)}}{\\partial \\textbf{W}_{hh}} = \\dfrac{\\partial L^{(t)}}{\\partial \\textbf{o}^{(t)}} \\times \\dfrac{\\partial \\textbf{o}^{(t)}}{\\partial \\textbf{h}^{(t)}} \\times \\left ( \\sum^t_{k=1}\\dfrac{\\partial \\textbf{h}^{(t)}}{\\partial \\textbf{h}^{(k)}} \\times \\dfrac{\\partial \\textbf{h}^{(k)}}{\\partial \\textbf{W}_{hh}} \\right )\n",
    "\n",
    "$$\n",
    "\n",
    "Aqui, $\\small \\dfrac{\\partial \\textbf{h}^{(t)}}{\\partial \\textbf{h}^{(k)}}$ é calculado como uma multiplicação de passos de tempo adjacentes:\n",
    "$$\n",
    "\\small \\dfrac{\\partial \\textbf{h}^{(t)}}{\\partial \\textbf{h}^{k}} = \\prod ^t_{i=k+1} \\dfrac{\\partial \\textbf{h}^{(i)}}{\\partial \\textbf{h}^{(i-1)}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorrência oculta versus recorrência de saída\n",
    "Até agora, você viu redes recorrentes nas quais a camada oculta tem a propriedade recorrente. No entanto, observe que existe um modelo alternativo em que a conexão recorrente vem da camada de saída. Nesse caso, as ativações líquidas da camada de saída na etapa de tempo anterior, $\\small \\textbf{o}^{(t-1)}$, podem ser adicionadas de duas maneiras:\n",
    "* Para a camada oculta no passo de tempo atual, $\\small \\textbf{h}^t$ (mostrado na figura a seguir como recorrência de saída para oculta)\n",
    "* Para a camada de saída no passo de tempo atual, $\\small \\textbf{o}^{t}$ (mostrado na figura a seguir como recorrência de saída para saída)\n",
    "\n",
    "![](imagens\\recorrencia_saida.PNG)\n",
    "\n",
    "Conforme mostrado na figura anterior, as diferenças entre essas arquiteturas podem ser vistas claramente nas conexões recorrentes. Seguindo nossa notação, os pesos associados à conexão recorrente serão denotados para a recorrência oculta para oculta por $\\small \\textbf{W}_{hh}$, para a recorrência saída para oculta por $\\small \\textbf{W}_{oh}$, e para a recorrência saída para saída por $\\small \\textbf{W}_{oo}$. Em alguns artigos da literatura, os pesos associados às conexões recorrentes também são denotados por $\\small \\textbf{W}_{rec}$.\n",
    "\n",
    "Para ver como isso funciona na prática, vamos calcular manualmente a passagem direta para um desses tipos recorrentes. Usando a *API TensorFlow Keras*, uma camada recorrente pode ser definida por meio da *SimpleRNN*, que é semelhante à recorrência de saída para saída. No código a seguir, criaremos uma camada recorrente do *SimpleRNN* e executaremos uma passagem direta em uma sequência de entrada de comprimento 3 para calcular a saída. Também calcularemos manualmente a passagem direta e compararemos os resultados com os do *SimpleRNN*. Primeiro, vamos criar a camada e atribuir os pesos para nossos cálculos manuais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape: (5, 2)\n",
      "W_oo shape: (2, 2)\n",
      "b_h shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "tf.autograph.set_verbosity(0)\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=2, use_bias=True, \n",
    "    return_sequences=True)\n",
    "rnn_layer.build(input_shape=(None, None, 5))\n",
    "\n",
    "w_xh, w_oo, b_h = rnn_layer.weights\n",
    "\n",
    "print('W_xh shape:', w_xh.shape)\n",
    "print('W_oo shape:', w_oo.shape)\n",
    "print('b_h shape:', b_h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A forma de entrada para esta camada é `(None, None, 5)`, onde a primeira dimensão é a dimensão do lote (usando `None` para tamanho de lote variável), a segunda dimensão corresponde à sequência (usando `None` para o comprimento variável da sequência) e a última dimensão corresponde às características. Observe que definimos `return_sequences=True`, que, para uma sequência de entrada de comprimento 3, resultará na sequência de saída $\\small \\left \\langle \\textbf{o}^{(0)},\\textbf{o}^{(1)}, \\textbf{o}^{(2)} \\right \\rangle$. Caso contrário, ele retornaria apenas a saída final, $\\textbf{o}^{(2)}$.\n",
    "\n",
    "Agora, vamos chamar a passagem direta no `rnn_layer` e calcular manualmente as saídas em cada passo de tempo e compará-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 =>\n",
      "   Input           : [[1. 1. 1. 1. 1.]]\n",
      "   Hidden          : [[0.41464037 0.96012145]]\n",
      "   Output (manual) : [[0.39240566 0.74433106]]\n",
      "   SimpleRNN output: [0.39240566 0.74433106]\n",
      "\n",
      "Time step 1 =>\n",
      "   Input           : [[2. 2. 2. 2. 2.]]\n",
      "   Hidden          : [[0.82928073 1.9202429 ]]\n",
      "   Output (manual) : [[0.80116504 0.99129474]]\n",
      "   SimpleRNN output: [0.80116504 0.99129474]\n",
      "\n",
      "Time step 2 =>\n",
      "   Input           : [[3. 3. 3. 3. 3.]]\n",
      "   Hidden          : [[1.243921  2.8803644]]\n",
      "   Output (manual) : [[0.95468265 0.9993069 ]]\n",
      "   SimpleRNN output: [0.95468265 0.9993069 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_seq = tf.convert_to_tensor(\n",
    "    [[1.0]*5, [2.0]*5, [3.0]*5],\n",
    "    dtype=tf.float32)\n",
    "\n",
    "\n",
    "## output of SimepleRNN:\n",
    "output = rnn_layer(tf.reshape(x_seq, shape=(1, 3, 5)))\n",
    "\n",
    "## manually computing the output:\n",
    "out_man = []\n",
    "for t in range(len(x_seq)):\n",
    "    xt = tf.reshape(x_seq[t], (1, 5))\n",
    "    print('Time step {} =>'.format(t))\n",
    "    print('   Input           :', xt.numpy())\n",
    "    \n",
    "    ht = tf.matmul(xt, w_xh) + b_h    \n",
    "    print('   Hidden          :', ht.numpy())\n",
    "    \n",
    "    if t>0:\n",
    "        prev_o = out_man[t-1]\n",
    "    else:\n",
    "        prev_o = tf.zeros(shape=(ht.shape))\n",
    "        \n",
    "    ot = ht + tf.matmul(prev_o, w_oo)\n",
    "    ot = tf.math.tanh(ot)\n",
    "    out_man.append(ot)\n",
    "    print('   Output (manual) :', ot.numpy())\n",
    "    print('   SimpleRNN output:'.format(t), output[0][t].numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nosso cálculo direto manual, usamos a função de ativação da tangente hiperbólica (tanh), uma vez que também é usada na `SimpleRNN` (a ativação padrão). Como você pode ver nos resultados impressos, as saídas dos cálculos de encaminhamento manual correspondem exatamente à saída da camada `SimpleRNN` em cada etapa de tempo. Espero que esta tarefa prática tenha esclarecido você sobre os mistérios das redes recorrentes.\n",
    "\n",
    "### Os desafios de aprender interações de longo prazo\n",
    "\n",
    "BPTT, que foi brevemente mencionado anteriormente, apresenta alguns novos desafios. Por causa do fator multiplicativo,$\\small \\dfrac{\\partial \\textbf{h}^{(t)}}{\\partial \\textbf{h}^{(k)}}$, ao calcular os gradientes de uma função de perda, surgem os chamados problemas de **gradiente de fuga e explosão**. Esses problemas são explicados pelos exemplos na figura a seguir, que mostra uma RNN com apenas uma unidade oculta para simplificar:\n",
    "\n",
    "![](imagens\\gradiente_fuga_explosao.PNG)\n",
    "\n",
    "\n",
    "Basicamente, $\\small \\dfrac{\\partial \\textbf{h}^{(t)}}{\\partial \\textbf{h}^{(k)}}$ tem $\\small t – k$ multiplicações; portanto, multiplicar o peso, $\\small w$, por ele mesmo $\\small t – k$ vezes resulta em um fator, $\\small w^{t-w}$ . Como resultado, se $\\small |w|< 1$, esse fator se torna muito pequeno quando $\\small t – k$ é grande. Por outro lado, se o peso da aresta recorrente for $\\small |w|> 1$ , então $w^{t-k}$ se torna muito grande quando $\\small t – k$ é grande. Observe que $\\small t – k$ grande se refere a dependências de longo alcance. Podemos ver que uma solução ingênua para evitar gradientes de fuga ou explosão pode ser alcançada garantindo $\\small |w| = 1$.\n",
    "\n",
    "Na prática, existem pelo menos três soluções para este problema:\n",
    "* *Gradient clipping*\n",
    "* *TBPTT*\n",
    "* *LSTM*\n",
    "\n",
    "Usando o *Gradient clipping*, especificamos um valor de corte ou limite para os gradientes e atribuímos esse valor de corte aos valores de gradiente que excedem esse valor. Em contraste, o *TBPTT* simplesmente limita ao número de passos de tempo que o sinal pode retropropagar após cada passagem para frente. Por exemplo, mesmo que a sequência tenha 100 elementos ou etapas, podemos retropropagar apenas as 20 etapas de tempo mais recentes.\n",
    "\n",
    "Embora tanto o *Gradient clipping* quanto o *TBPTT* possam resolver o problema do **gradiente explosivo**, o truncamento limita o número de etapas que o gradiente pode efetivamente retornar e atualizar adequadamente os pesos. Por outro lado, o *LSTM*, projetado em 1997 por *Sepp Hochreiter* e *Jürgen Schmidhuber*, tem tido mais sucesso em eliminar e explodir problemas de gradiente ao modelar dependências de longo alcance por meio de\n",
    "o uso de células de memória. Vamos discutir *LSTM* com mais detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Células de memória de longo prazo\n",
    "\n",
    "Como afirmado anteriormente, os *LSTMs* foram introduzidos pela primeira vez para superar o problema do gradiente de fuga. O bloco de construção de um *LSTM* é uma célula de memória, que essencialmente representa ou substitui a camada oculta de RNNs padrão.\n",
    "\n",
    "Em cada célula de memória, há uma aresta recorrente que tem o peso desejável, $\\small w = 1$, como discutimos, para superar os problemas de gradiente de fuga e explosão. Os valores associados a essa borda recorrente são chamados coletivamente de estado da célula. A estrutura desdobrada de uma célula *LSTM* moderna é mostrada na figura a seguir:\n",
    "\n",
    "![](imagens\\ltsm.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que o estado da célula do passo de tempo anterior, $\\small \\textbf{C}^{(t-1)}$, é modificado para obter o estado da célula no passo de tempo atual, $\\small \\textbf{C}^{(t)}$, sem ser multiplicado diretamente por nenhum fator de peso. O fluxo de informação nesta célula de memória é controlado por várias unidades de computação (frequentemente chamadas de portas) que serão descritas aqui. Na figura anterior,$\\small \\bigodot$ refere-se ao produto **elemento-a-elemento** (multiplicação elemento-a-elemento) e $\\small \\bigoplus$ significa s**oma-elemento** (adição elemento-a-elemento). Além disso, $\\small \\textbf{x}^{(t)}$ refere-se aos dados de entrada no tempo $\\small t$, e $\\small \\textbf{h}^{(t-1)}$ indica as unidades ocultas no tempo $\\small t – 1$. Quatro caixas são indicadas com uma função de ativação, seja a função sigmóide ($\\small \\sigma$) ou $\\small tanh$, e um conjunto de pesos; essas caixas aplicam uma combinação linear realizando multiplicações de matriz-vetor em suas entradas (que são $\\small \\textbf{h}^{(t-1)}$ e $\\small \\textbf{x}^{(t)}$). Essas unidades de computação com funções de ativação sigmóides, cujas unidades de saída são passadas por $\\small \\bigodot$, são chamadas de portas.\n",
    "\n",
    "Em uma célula *LSTM*, existem três tipos diferentes de portas, que são conhecidas como **porta de esquecimento**, porta de entrada e porta de saída:\n",
    "\n",
    "* A **porta de esquecimento** ($\\small f_t$) permite que a célula de memória redefina o estado da célula sem crescer indefinidamente. Na verdade, o portão de esquecimento decide quais informações podem passar e quais informações devem ser suprimidas. Agora, $\\small f_t$ é calculado da seguinte forma:\n",
    "\n",
    "$$\n",
    "\\small f_t = \\sigma(\\textbf{W}_{xf}\\textbf{x}^{(t)} + \\textbf{W}_{hf}\\textbf{h}^{(t-1)} + \\textbf{b}_f)\n",
    "$$\n",
    "\n",
    "\n",
    "* A **porta de entrada** ($\\small i_t$) e o **valor candidato** ($\\breve{C}_t$) são responsáveis ​​por atualizar o estado da célula. Eles são calculados da seguinte forma:\n",
    "\n",
    "$$\n",
    "\\small i_t = \\sigma ( \\textbf{W}_{xi}\\textbf{x}^{(t)} +  \\textbf{W}_{hi}\\textbf{h}^{(t-1)} + \\textbf{b}_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\small \\breve{C}_t = tanh (\\textbf{W}_{xc}\\textbf{x}^{(t)} + \\textbf{W}_{hc}\\textbf{h}^{(t-1)} + \\textbf{b}_c)\n",
    "$$\n",
    "\n",
    "O estado da célula no tempo t é calculado da seguinte forma:\n",
    "\n",
    "$$\n",
    "C^{t} = (C^{(t-1)} \\odot f_t) \\otimes (i_t \\odot \\breve{C}_t)\n",
    "$$\n",
    "\n",
    "A porta de saída ($\\small \\textbf{o}_t$) decide como atualizar os valores das unidades ocultas:\n",
    "\n",
    "$$\n",
    "\\small o_t = \\sigma (\\textbf{W}_{xo}\\textbf{x}^{(t)} + \\textbf{W}_{ho}\\textbf{h}^{(t-1)} + \\textbf{b}_o)\n",
    "$$\n",
    "\n",
    "Dado isso, as unidades ocultas no passo de tempo atual são calculadas da seguinte forma:\n",
    "\n",
    "$$\n",
    "\\small \\textbf{h}^{(t)} = \\textbf{o}_t \\odot \\: tanh (\\textbf{C}^{(t)})\n",
    "$$\n",
    "\n",
    "A estrutura de uma célula *LSTM* e seus cálculos subjacentes podem parecer muito complexos e difíceis de implementar. No entanto, a boa notícia é que o *TensorFlow* já implementou tudo em funções otimizadas de wr*apper, o que nos permite definir nossas células *LSTM* de maneira fácil e eficiente. Aplicaremos RNNs e LSTMs a conjuntos de dados do mundo real posteriormente.\n",
    "\n",
    "> #### Outros modelos RNN avançados\n",
    "> *LSTMs* fornecem uma abordagem básica para modelar dependências de longo alcance em sequências. No entanto, é importante notar que existem muitas variações de *LSTMs* descritas na literatura (An Empirical Exploration of Recurrent Network Architectures, Rafal Jozefowicz, Wojciech Zaremba e Ilya Sutskever, Proceedings of ICML, 2342-2350, 2015).\n",
    ">\n",
    "> Também merece destaque uma abordagem mais recente, *Gated Recurrent Unit* (GRU), proposta em 2014. As GRUs possuem uma arquitetura mais simples que as *LSTMs*; portanto, eles são computacionalmente mais eficientes, enquanto seu desempenho em algumas tarefas, como modelagem de música polifônica, é comparável aos *LSTMs*.\n",
    "\n",
    "### Implementando RNNs para modelagem de sequência no TensorFlow\n",
    "\n",
    "Agora que abordamos a teoria subjacente por trás das *RNNs*, estamos prontos para passar para a parte mais prática: implementar *RNNs* no TensorFlow. Durante o restante deste capítulo, aplicaremos *RNNs* a duas tarefas problemáticas comuns:\n",
    "1. Análise de sentimentos\n",
    "2. Modelagem de linguagem\n",
    "\n",
    "Esses dois projetos, que apresentaremos, são fascinantes e envolventes. Assim, em vez de fornecer o código de uma só vez, dividiremos a implementação em várias etapas e discutiremos o código em detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Projeto um – prevendo o sentimento das críticas de filmes do IMDb**\n",
    "\n",
    "Nesta seção e nas subseções seguintes, implementaremos uma *RNN* multicamada para análise de sentimentos usando uma arquitetura muitos-para-um.\n",
    "\n",
    "Na próxima seção, implementaremos um *RNN* muitos-para-muitos para uma aplicação de modelagem de linguagem. Embora os exemplos escolhidos sejam propositadamente simples para introduzir os principais conceitos de *RNNs*, a modelagem de linguagem tem uma ampla gama de aplicações interessantes, como a construção de chatbots – dando aos computadores a capacidade de conversar e interagir diretamente com humanos.\n",
    "\n",
    "### Preparando os dados de revisão do filme\n",
    "Nas etapas de pré-processamento, criamos um conjunto de dados limpo chamado `movie_data.csv`, que usaremos novamente agora. Primeiro, importaremos os módulos necessários e leremos os dados em um `DataFrame` pandas, da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se de que esse quadro de dados, `df`, consiste em duas colunas, chamadas `'review'` e `'sentiment'`, onde `'review'` contém o texto das resenhas de filmes (os recursos de entrada) e `'sentiment'` representa o rótulo de destino que queremos prever (0 refere-se ao sentimento negativo e 1 refere-se ao sentimento positivo).\n",
    "\n",
    "O componente de texto dessas resenhas de filmes são sequências de palavras, e o modelo *RNN* classifica cada sequência como uma resenha positiva (1) ou negativa (0). No entanto, antes de podermos alimentar os dados em um modelo *RNN*, precisamos aplicar várias etapas de pré-processamento:\n",
    "1. Crie um objeto de conjunto de dados do *TensorFlow* e divida-o em partições separadas de treinamento, teste e validação.\n",
    "2. Identifique as palavras exclusivas no conjunto de dados de treinamento.\n",
    "3. Mapeie cada palavra exclusiva para um número inteiro exclusivo e codifique o texto da revisão em números inteiros codificados (um índice de cada palavra exclusiva).\n",
    "4. Divida o conjunto de dados em minilotes como entrada para o modelo.\n",
    "\n",
    "Vamos prosseguir com a primeira etapa: criar um conjunto de dados do *TensorFlow* a partir deste quadro de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n",
      "b'OK... so... I really like Kris Kristofferson and h' 0\n",
      "b'***SPOILER*** Do not read this, if you think about' 0\n"
     ]
    }
   ],
   "source": [
    "# Passo 1: Criando um Dataset\n",
    "\n",
    "target = df.pop('sentiment')\n",
    "\n",
    "ds_raw = tf.data.Dataset.from_tensor_slices(\n",
    "    (df.values, target.values))\n",
    "\n",
    "## inspection:\n",
    "for ex in ds_raw.take(3):\n",
    "    tf.print(ex[0].numpy()[0][:50], ex[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos dividi-lo em conjuntos de dados de treinamento, teste e validação. Todo o conjunto de dados contém 50.000 exemplos. Manteremos os primeiros 25.000 exemplos para avaliação (conjunto de dados de teste de retenção) e, em seguida, 20.000 exemplos serão usados para treinamento e 5.000 para validação. O código é o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds_raw = ds_raw.shuffle(50000, reshuffle_each_iteration=False)\n",
    "\n",
    "ds_raw_test = ds_raw.take(25000)                 # Separa 25.000 amostras das 50.000\n",
    "ds_raw_train_valid = ds_raw.skip(25000)          # Pula as 25.000 amostras do conjunto anterior e salva em uma variável \n",
    "ds_raw_train = ds_raw_train_valid.take(20000)    # Da variável anterior, vamos pegas 20.000 e salvar numa variável.\n",
    "ds_raw_valid = ds_raw_train_valid.skip(20000)    # Vamos pular 20.000 amostras e salvar numa variável. Que será somente 5.000 (que sobrou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para preparar os dados para entrada em uma RN, precisamos codificá-los em valores numéricos, conforme mencionado nas etapas 2 e 3. Para fazer isso, primeiro encontraremos as palavras exclusivas (*tokens*) no conjunto de dados de treinamento. Embora encontrar *tokens* exclusivos seja um processo para o qual podemos usar conjuntos de dados *Python*, pode ser mais eficiente usar a classe `Counter` do pacote `collections`, que faz parte da biblioteca padrão do *Python*.\n",
    "\n",
    "No código a seguir, instanciaremos um novo objeto `Counter` (`token_counts`) que coletará as frequências de palavras exclusivas. Observe que neste aplicativo específico (e em contraste com o modelo *bag-of-words*), estamos interessados apenas no conjunto de palavras únicas e não exigiremos a contagem de palavras, que é criada como um produto secundário. Para dividir o texto em palavras (ou *tokens*), o pacote `tensorflow_datasets` fornece uma classe `Tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 87007\n"
     ]
    }
   ],
   "source": [
    "## Passo 2: Encontrar tokens (palavras) unicas\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "\n",
    "token_counts = Counter()\n",
    "\n",
    "for example in ds_raw_train:\n",
    "    tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print('Vocab-size:', len(token_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, vamos mapear cada palavra única para um inteiro único. Isso pode ser feito manualmente usando um dicionário Python, onde as chaves são os tokens exclusivos (palavras) e o valor associado a cada chave é um inteiro único. No entanto, o pacote `tensorflow_datasets` já fornece uma classe, `TokenTextEncoder`, que podemos usar para criar esse mapeamento e codificar todo o conjunto de dados. Primeiro, criaremos um objeto codificador da classe `TokenTextEncoder` passando os tokens exclusivos (`token_counts` contém os tokens e suas contagens, embora aqui, suas contagens não sejam necessárias, portanto, serão ignoradas). Chamar o método `encoder.encode()` converterá seu texto de entrada em uma lista de valores inteiros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232, 9, 35, 1123]\n"
     ]
    }
   ],
   "source": [
    "## Passo 3: Encode tokens únicos (palavras) para inteiros\n",
    "\n",
    "encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n",
    "example_str = 'This is a example!'\n",
    "print(encoder.encode(example_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que pode haver alguns *tokens* nos dados de validação ou teste que não estão presentes nos dados de treinamento e, portanto, não estão incluídos no mapeamento. Se tivermos $\\small q$ *tokens* (que é o tamanho de `token_counts` passado para o `TokenTextEncoder`, que neste caso é 87.007), todos os *tokens* que não foram vistos antes e, portanto, não estão incluídos em `token_counts`, receberão o inteiro $\\small q + 1$ (que será 87.008 no nosso caso). Em outras palavras, o índice $\\small q + 1$ é reservado para palavras desconhecidas.\n",
    "\n",
    "Outro valor reservado é o inteiro 0, que serve como espaço reservado para ajustar o comprimento da sequência. Mais tarde, quando estivermos construindo um modelo *RNN* no *TensorFlow*, consideraremos esses dois espaços reservados, 0 e $\\small q + 1$, com mais detalhes.\n",
    "\n",
    "Podemos usar o método `map()` dos objetos do conjunto de dados para transformar cada texto no conjunto de dados de acordo, assim como aplicaríamos qualquer outra transformação a um conjunto de dados. No entanto, há um pequeno problema: aqui, os dados de texto são incluídos em objetos tensores, que podemos acessar chamando o método `numpy()` em um tensor no modo de execução antecipada. Mas durante as transformações pelo método `map()`, a execução antecipada será desabilitada. Para resolver este problema, podemos definir duas funções. A primeira função tratará os tensores de entrada como se o modo de execução ansioso estivesse habilitado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Passo 3-A: defina uma função para a tranformação\n",
    "\n",
    "def encode(text_tensor, label):\n",
    "    text = text_tensor.numpy()[0]\n",
    "    encoded_text = encoder.encode(text)\n",
    "    return encoded_text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na segunda função, envolveremos a primeira função usando `tf.py_function` para convertê-la em um operador *TensorFlow*, que pode ser usado por meio de seu método `map()`. Este processo de codificação de texto em uma lista de inteiros pode ser realizado usando o seguinte código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da sequência: (24,)\n",
      "Tamanho da sequência: (179,)\n",
      "Tamanho da sequência: (262,)\n",
      "Tamanho da sequência: (535,)\n",
      "Tamanho da sequência: (130,)\n"
     ]
    }
   ],
   "source": [
    "## Passo 3-B: Empacotar a Função encode na Tf. Op\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "    return tf.py_function(encode, inp=[text, label],\n",
    "    Tout=(tf.int64, tf.int64))\n",
    "\n",
    "ds_train = ds_raw_train.map(encode_map_fn)\n",
    "ds_valid = ds_raw_valid.map(encode_map_fn)\n",
    "ds_test = ds_raw_test.map(encode_map_fn)\n",
    "\n",
    "#  Checando o Shape de alguns exemplos\n",
    "tf.random.set_seed(1)\n",
    "for example in ds_train.shuffle(1000).take(5):\n",
    "    print(f\"Tamanho da sequência: {example[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até agora, convertemos sequências de palavras em sequências de inteiros. No entanto, há um problema que ainda precisamos resolver — as sequências atualmente têm comprimentos diferentes (como mostrado no resultado da execução do código anterior para cinco exemplos escolhidos aleatoriamente). Embora, em geral, as RNNs possam lidar com sequências com comprimentos diferentes, ainda precisamos garantir que todas as sequências em um minilote tenham o mesmo comprimento para armazená-las de forma eficiente em um tensor.\n",
    "\n",
    "Para dividir um conjunto de dados que possui elementos com formas diferentes em mini-lotes, o *TensorFlow* fornece um método diferente, *padded_batch()* (em vez de `batch()`), que preencherá automaticamente os elementos consecutivos que devem ser combinados em um lote com valores de espaço reservado (0s) para que todas as sequências dentro de um lote tenham a mesma forma. Para ilustrar isso com um exemplo prático, vamos pegar um pequeno subconjunto de tamanho 8 do conjunto de dados de treinamento, `ds_train`, e aplicar o método *padded_batch()* a esse subconjunto com `batch_size=4`. Também imprimiremos os tamanhos dos elementos individuais antes de combiná-los em minilotes, bem como as dimensões dos minilotes resultantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho individual: (119,)\n",
      "Tamanho individual: (688,)\n",
      "Tamanho individual: (308,)\n",
      "Tamanho individual: (204,)\n",
      "Tamanho individual: (326,)\n",
      "Tamanho individual: (240,)\n",
      "Tamanho individual: (127,)\n",
      "Tamanho individual: (453,)\n"
     ]
    }
   ],
   "source": [
    "## Selecionar um pequeno conjunto de dados:\n",
    "\n",
    "ds_subset = ds_train.take(8)\n",
    "for example in ds_subset:\n",
    "    print(f\"Tamanho individual: {example[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch dimension: (4, 688)\n",
      "Batch dimension: (4, 453)\n"
     ]
    }
   ],
   "source": [
    "## Loteando o conjunto de dados\n",
    "\n",
    "ds_batch = ds_subset.padded_batch(4, padded_shapes=([-1], []))\n",
    "\n",
    "for batch in ds_batch:\n",
    "    print(f\"Batch dimension: {batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode observar nas formas de tensor impressas, o número de colunas (ou seja, `.shape[1]`) no primeiro lote é `688`, resultado da combinação dos quatro primeiros exemplos em um único lote e do uso do tamanho máximo desses exemplos. Isso significa que os outros três exemplos neste lote são preenchidos o quanto for necessário para corresponder a esse tamanho.\n",
    "\n",
    "Da mesma forma, o segundo lote mantém o tamanho máximo de seus quatro exemplos individuais, que é `453`, e preenche os outros exemplos para que seu comprimento seja menor que o comprimento máximo.\n",
    "\n",
    "Vamos dividir todos os três conjuntos de dados em minilotes com um tamanho de lote de 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ds_train.padded_batch(\n",
    "    32, padded_shapes=([-1],[]))\n",
    "\n",
    "valid_data = ds_valid.padded_batch(\n",
    "    32, padded_shapes=([-1],[]))\n",
    "\n",
    "test_data = ds_test.padded_batch(\n",
    "    32, padded_shapes=([-1],[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, os dados estão em um formato adequado para um modelo RNN, que vamos implementar. No próximo tópico, no entanto, discutiremos primeiro a incorporação de recursos, que é uma etapa de pré-processamento opcional, mas altamente recomendada, usada para reduzir a dimensionalidade dos vetores de palavras.\n",
    "\n",
    "### Incorporando camadas para codificação de frases\n",
    "Durante a preparação dos dados na etapa anterior, geramos sequências de mesmo comprimento. Os elementos dessas sequências eram números inteiros que correspondiam aos `índices` de palavras únicas. Esses índices de palavras podem ser convertidos em recursos de entrada de várias maneiras diferentes. Uma maneira ingênua é aplicar a codificação *one-hot* para converter os índices em vetores de zeros e uns. Em seguida, cada palavra será mapeada para um vetor cujo tamanho é o número de palavras únicas em todo o conjunto de dados. Dado que o número de palavras únicas (o tamanho do vocabulário) pode ser da ordem de $\\small 10^4 - 10^5$, que também será o número de nossos recursos de entrada, um modelo treinado em tais recursos pode sofrer a **maldição da dimensionalidade**. Além disso, esses recursos são muito esparsos, pois todos são zero, exceto um.\n",
    "\n",
    "Uma abordagem mais elegante é mapear cada palavra para um vetor de tamanho fixo com elementos de valor real (não necessariamente inteiros). Em contraste com os vetores codificados *one-hot*, podemos usar vetores de tamanho finito para representar um número infinito de números reais. (Em teoria, podemos extrair infinitos números reais de um determinado intervalo, por exemplo [–1, 1].)\n",
    "\n",
    "Essa é a ideia por trás da incorporação (**embedding**), que é uma técnica de aprendizado de recursos que podemos utilizar aqui para aprender automaticamente os recursos importantes para representar as palavras em nosso conjunto de dados. Dado o número de palavras únicas, $\\small n_{words}$, podemos selecionar o tamanho dos vetores de incorporação (também conhecido como, a dimensão de incorporação) para ser muito menor que o número de palavras únicas ($\\small embedding_{dims} << n_{words}$) para representar todo o vocabulário como recursos de entrada.\n",
    "\n",
    "As vantagens da incorporação sobre a codificação *one-hot* são as seguintes:\n",
    "• Uma redução na dimensionalidade do espaço de recursos para diminuir o efeito da maldição da dimensionalidade\n",
    "• A extração de recursos salientes desde a camada de incorporação em uma RN pode ser otimizada (ou aprendida)\n",
    "\n",
    "A representação esquemática a seguir mostra como a incorporação funciona mapeando índices de token para uma matriz de incorporação treinável:\n",
    "\n",
    "![](imagens\\embedding.PNG)\n",
    "\n",
    "\n",
    "Dado um conjunto de tokens de tamanho $\\small n + 2$ ($\\small n$ é o tamanho do conjunto de *tokens*, mais o índice 0 é reservado para o preenchimento e $\\small n + 1$ é para as palavras não presentes no conjunto de *tokens*), uma matriz de incorporação de tamanho $\\small (n + 2) \\times embedding-dim$ será criado onde cada linha desta matriz representa recursos numéricos associados a um *token*.\n",
    "\n",
    "Portanto, quando um índice inteiro, $\\small i$, for fornecido como entrada para a incorporação, ele procurará a linha correspondente da matriz no índice $\\small i$ e retornará os recursos numéricos. A matriz de incorporação serve como camada de entrada para nossos modelos RN.\n",
    "\n",
    "Na prática, a criação de uma camada de incorporação pode ser feita simplesmente usando `tf.keras.layers.Embedding`. Vamos ver um exemplo onde vamos criar um modelo e adicionar uma camada de embedding, como segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embed-layer (Embedding)     (None, 20, 6)             600       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600\n",
      "Trainable params: 600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(input_dim=100,\n",
    "                    output_dim=6,\n",
    "                    input_length=20,\n",
    "                    name=\"embed-layer\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A entrada para este modelo (camada de incorporação) deve ter a classificação 2 com dimensionalidade $\\small batchsize \\times input\\_length$, onde $\\small input\\_length$ é o comprimento das seqüências (no caso aqui, definida como 20 através do argumento `input_length`). Por exemplo, uma sequência de entrada no minilote pode ser $\\small \\left \\langle  14,43,52, 1,8,19,67,83,10,7,42,87,56,18,94,17,67,90, 6,39 \\right \\rangle$, onde cada elemento desta sequência é o índice das palavras únicas. A saída terá dimensionalidade $\\small batchsize \\times input\\_length \\times embedding\\_dim$, onde $\\small embedding\\_dim$ é o tamanho dos recursos de incorporação (aqui, definido como 6 via `output_dim`). O outro argumento fornecido à camada de incorporação, `input_dim`, corresponde aos valores inteiros exclusivos que o modelo receberá como entrada (por exemplo, `n + 2`, definido aqui como `100`). Portanto, a matriz de incorporação neste caso tem o tamanho `100 × 6`.\n",
    "\n",
    "> ##### Lidando com comprimentos de sequência variáveis\n",
    "> Observe que o argumento `input_length` não é necessário e podemos usar `None` para casos em que os comprimentos das sequências de entrada variam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo um modelo *RNN*\n",
    "Agora estamos prontos para construir um modelo *RNN*. Usando a classe Keras `Sequential`, podemos combinar a camada de incorporação (*embedding*), as camadas recorrentes da *RNN* e as camadas não recorrentes totalmente conectadas. Para as camadas recorrentes, podemos usar qualquer uma das seguintes implementações:\n",
    "* `SimpleRNN`: uma camada *RNN* regular, ou seja, uma camada recorrente totalmente conectada\n",
    "* `LSTM`: uma *RNN* de memória de curto prazo longo, que é útil para capturar as dependências de longo prazo\n",
    "* `GRU`: uma camada recorrente com uma unidade recorrente fechada, como alternativa aos `LSTMs`\n",
    "\n",
    "Para ver como um modelo *RNN* multicamada pode ser construído usando uma dessas camadas recorrentes, no exemplo a seguir, criaremos um modelo *RNN*, começando com uma camada de incorporação com `input_dim=1000` e `output_dim=32`. Em seguida, serão adicionadas duas camadas recorrentes do tipo `SimpleRNN`. Por fim, adicionaremos uma camada totalmente conectada não recorrente como camada de saída, que retornará um único valor de saída como previsão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          32000     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, None, 32)          2080      \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,193\n",
      "Trainable params: 36,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          320000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 32)          8320      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 336,673\n",
      "Trainable params: 336,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Usando uma RNN com LTSM \n",
    "from tensorflow.keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 32)          320000    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 32)          6336      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 32)                6336      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332,705\n",
      "Trainable params: 332,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Um exemplo com uma camada GRU\n",
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(GRU(32, return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode ver, construir um modelo *RNN* usando essas camadas recorrentes é bastante simples. Na próxima subseção, voltaremos à nossa tarefa de análise de sentimentos e construiremos um modelo *RNN* para resolver isso.\n",
    "\n",
    "### Construindo um modelo *RNN* para a tarefa de análise de sentimento\n",
    "\n",
    "Como temos sequências muito longas, usaremos uma camada *LSTM* para contabilizar os efeitos de longo prazo. Além disso, colocaremos a camada *LSTM* dentro de um wrapper `Bidirectional`, que fará com que as camadas recorrentes passem pelas sequências de entrada de ambas as direções, do início ao fim, bem como no sentido inverso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embed-layer (Embedding)     (None, None, 20)          1740180   \n",
      "                                                                 \n",
      " bidir-lstm (Bidirectional)  (None, 128)               43520     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,792,021\n",
      "Trainable params: 1,792,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willi\\OneDrive\\Documentos\\4. GitHub\\Machine_Learning_Studies\\Modelagem Sequencial usando RNN.ipynb Cell 37'\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=23'>24</a>\u001b[0m \u001b[39m## Compilando e treinando:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=24'>25</a>\u001b[0m bi_lstm_model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=25'>26</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(\u001b[39m1e-3\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=26'>27</a>\u001b[0m     loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=27'>28</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=29'>30</a>\u001b[0m history \u001b[39m=\u001b[39m bi_lstm_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=30'>31</a>\u001b[0m     train_data, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=31'>32</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_data, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=32'>33</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=34'>35</a>\u001b[0m \u001b[39m## Avaliando os dados\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000036?line=35'>36</a>\u001b[0m test_results\u001b[39m=\u001b[39m bi_lstm_model\u001b[39m.\u001b[39mevaluate(test_data)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1401'>1402</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1402'>1403</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1403'>1404</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1404'>1405</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1405'>1406</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1406'>1407</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1407'>1408</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1408'>1409</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1409'>1410</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/keras/engine/training.py?line=1410'>1411</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=975'>976</a>\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=976'>977</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=977'>978</a>\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=978'>979</a>\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=979'>980</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=980'>981</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=981'>982</a>\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=982'>983</a>\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/def_function.py?line=983'>984</a>\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=2449'>2450</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=2450'>2451</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=2451'>2452</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=2452'>2453</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=2453'>2454</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1859'>1860</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1860'>1861</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1861'>1862</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1862'>1863</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1863'>1864</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1864'>1865</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=1865'>1866</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=494'>495</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=495'>496</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=508'>509</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/function.py?line=509'>510</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/willi/anaconda3/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_dim = 20\n",
    "vocab_size = len(token_counts) + 2\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "## Construindo o modelo \n",
    "bi_lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        name='embed-layer'),\n",
    "    \n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, name='lstm-layer'),\n",
    "        name='bidir-lstm'), \n",
    "\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "bi_lstm_model.summary()\n",
    "\n",
    "## Compilando e treinando:\n",
    "bi_lstm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = bi_lstm_model.fit(\n",
    "    train_data, \n",
    "    validation_data=valid_data, \n",
    "    epochs=10)\n",
    "\n",
    "## Avaliando os dados\n",
    "test_results= bi_lstm_model.evaluate(test_data)\n",
    "print('Test Acc.: {:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após treinar este modelo por 10 épocas, a avaliação nos dados de teste mostra **81%** de precisão. (Observe que esse resultado não é o melhor quando comparado aos métodos de última geração usados no conjunto de dados do IMDb. O objetivo era simplesmente mostrar como o RNN funciona.)\n",
    "\n",
    ">##### Mais sobre o RNN bidirecional\n",
    "> O wrapper `Bidirectional` faz duas passagens em cada sequência de entrada: uma passagem para frente e uma passagem reversa ou para trás (observe que isso não deve ser confundido com as passagens para frente e para trás no contexto de retropropagação). Os resultados dessas passagens para frente e para trás serão concatenados por padrão. Mas se você quiser mudar esse comportamento, você pode definir o argumento `merge_mode` para `'sum'` (para soma), `'mul'` (para multiplicar os resultados das duas passagens), `'ave'` (para tirar a média das duas) , `'concat'` (que é o padrão) ou `None`, que retorna os dois tensores em uma lista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos tentar outros tipos de camadas recorrentes, como `SimpleRNN`. No entanto, como se vê, um modelo construído com camadas recorrentes regulares não será capaz de alcançar um bom desempenho preditivo (mesmo nos dados de treinamento). Por exemplo, se você tentar substituir a camada *LSTM* bidirecional no código anterior por uma camada `SimpleRNN` unidirecional e treinar o modelo em sequências completas, poderá observar que a perda nem diminuirá durante o treinamento. **A razão é que as sequências neste conjunto de dados são muito longas**, portanto, um modelo com uma camada `SimpleRNN` não pode aprender as dependências de longo prazo e pode sofrer com problemas de **gradiente de fuga ou explosão**.\n",
    "\n",
    "Para obter um desempenho preditivo razoável neste conjunto de dados usando um `SimpleRNN`, podemos truncar as sequências. Além disso, utilizando nosso \"conhecimento de domínio\", podemos supor que os últimos parágrafos de uma crítica de filme podem conter a maioria das informações sobre seu sentimento. Portanto, podemos nos concentrar apenas na última parte de cada revisão. Para fazer isso, vamos definir uma função auxiliar, `preprocess_datasets()`, para combinar as etapas de pré-processamento `2-4`. Um argumento opcional para esta função é `max_seq_length`, que determina quantos *tokens* de cada revisão devem ser usados. Por exemplo, se definirmos `max_seq_length=100` e um comentário tiver mais de 100 *tokens*, apenas os últimos 100 *tokens* serão usados. Se `max_seq_length` for definido como `None`, as sequências de comprimento total serão usadas como antes. Tentar valores diferentes para `max_seq_length` nos dará mais informações sobre a capacidade de diferentes modelos de RNN para lidar com sequências longas.\n",
    "\n",
    "O código para a função `preprocess_datasets()` é o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def preprocess_datasets(\n",
    "    ds_raw_train, \n",
    "    ds_raw_valid, \n",
    "    ds_raw_test,\n",
    "    max_seq_length=None,\n",
    "    batch_size=32):\n",
    "    \n",
    "    ## Passo 1: (Já feito => Cria o DataSet)\n",
    "    ## Passo 2: (Encontra os tokens únicos (palavras)\n",
    "    tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "    token_counts = Counter()\n",
    "\n",
    "    for example in ds_raw_train:\n",
    "        tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
    "        if max_seq_length is not None:\n",
    "            tokens = tokens[-max_seq_length:]\n",
    "        token_counts.update(tokens)\n",
    "\n",
    "    print('Vocab-size:', len(token_counts))\n",
    "\n",
    "\n",
    "    ## Passo 3: Encode os textos\n",
    "    encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n",
    "    def encode(text_tensor, label):\n",
    "        text = text_tensor.numpy()[0]\n",
    "        encoded_text = encoder.encode(text)\n",
    "        if max_seq_length is not None:\n",
    "            encoded_text = encoded_text[-max_seq_length:]\n",
    "        return encoded_text, label\n",
    "\n",
    "    def encode_map_fn(text, label):\n",
    "        return tf.py_function(encode, inp=[text, label], \n",
    "                              Tout=(tf.int64, tf.int64))\n",
    "\n",
    "    ds_train = ds_raw_train.map(encode_map_fn)\n",
    "    ds_valid = ds_raw_valid.map(encode_map_fn)\n",
    "    ds_test = ds_raw_test.map(encode_map_fn)\n",
    "\n",
    "    ## Passo 4: Lotea o DataSet\n",
    "    train_data = ds_train.padded_batch(\n",
    "        batch_size, padded_shapes=([-1],[]))\n",
    "\n",
    "    valid_data = ds_valid.padded_batch(\n",
    "        batch_size, padded_shapes=([-1],[]))\n",
    "\n",
    "    test_data = ds_test.padded_batch(\n",
    "        batch_size, padded_shapes=([-1],[]))\n",
    "\n",
    "    return (train_data, valid_data, \n",
    "            test_data, len(token_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, vamos definir outra função auxiliar, `build_rnn_model()`, para construir modelos com diferentes arquiteturas de forma mais conveniente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "def build_rnn_model(embedding_dim, vocab_size,\n",
    "                    recurrent_type='SimpleRNN',\n",
    "                    n_recurrent_units=64,\n",
    "                    n_recurrent_layers=1,\n",
    "                    bidirectional=True):\n",
    "\n",
    "    tf.random.set_seed(1)\n",
    "\n",
    "    # Constrói o modelo\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(\n",
    "        Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            name='embed-layer')\n",
    "    )\n",
    "    \n",
    "    for i in range(n_recurrent_layers):\n",
    "        return_sequences = (i < n_recurrent_layers-1)\n",
    "            \n",
    "        if recurrent_type == 'SimpleRNN':\n",
    "            recurrent_layer = SimpleRNN(\n",
    "                units=n_recurrent_units, \n",
    "                return_sequences=return_sequences,\n",
    "                name='simprnn-layer-{}'.format(i))\n",
    "        elif recurrent_type == 'LSTM':\n",
    "            recurrent_layer = LSTM(\n",
    "                units=n_recurrent_units, \n",
    "                return_sequences=return_sequences,\n",
    "                name='lstm-layer-{}'.format(i))\n",
    "        elif recurrent_type == 'GRU':\n",
    "            recurrent_layer = GRU(\n",
    "                units=n_recurrent_units, \n",
    "                return_sequences=return_sequences,\n",
    "                name='gru-layer-{}'.format(i))\n",
    "        \n",
    "        if bidirectional:\n",
    "            recurrent_layer = Bidirectional(\n",
    "                recurrent_layer, name='bidir-'+recurrent_layer.name)\n",
    "            \n",
    "        model.add(recurrent_layer)\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, usando essas duas funções auxiliares bastante gerais, mas convenientes, podemos comparar prontamente diferentes modelos RNN com diferentes comprimentos de sequência de entrada. Como exemplo, no código a seguir, tentaremos um modelo com uma única camada recorrente do tipo `SimpleRNN` enquanto truncamos as sequências para um comprimento máximo de 100 *tokens*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 58063\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embed-layer (Embedding)     (None, None, 20)          1161300   \n",
      "                                                                 \n",
      " bidir-simprnn-layer-0 (Bidi  (None, 128)              10880     \n",
      " rectional)                                                      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,180,501\n",
      "Trainable params: 1,180,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "embedding_dim = 20\n",
    "max_seq_length = 100\n",
    "\n",
    "train_data, valid_data, test_data, n = preprocess_datasets(\n",
    "    ds_raw_train, ds_raw_valid, ds_raw_test, \n",
    "    max_seq_length=max_seq_length, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "vocab_size = n + 2\n",
    "\n",
    "rnn_model = build_rnn_model(\n",
    "    embedding_dim, vocab_size,\n",
    "    recurrent_type='SimpleRNN', \n",
    "    n_recurrent_units=64,\n",
    "    n_recurrent_layers=1,\n",
    "    bidirectional=True)\n",
    "\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 173s 275ms/step - loss: 0.7013 - accuracy: 0.5030 - val_loss: 0.6968 - val_accuracy: 0.5040\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 177s 282ms/step - loss: 0.6858 - accuracy: 0.5490 - val_loss: 0.6403 - val_accuracy: 0.6286\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 176s 281ms/step - loss: 0.4813 - accuracy: 0.7696 - val_loss: 0.4830 - val_accuracy: 0.7886\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 176s 282ms/step - loss: 0.2786 - accuracy: 0.8864 - val_loss: 0.5534 - val_accuracy: 0.7630\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 176s 282ms/step - loss: 0.1624 - accuracy: 0.9371 - val_loss: 0.6887 - val_accuracy: 0.7518\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 176s 281ms/step - loss: 0.0504 - accuracy: 0.9829 - val_loss: 1.0899 - val_accuracy: 0.7372\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 178s 284ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 1.3421 - val_accuracy: 0.7308\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 176s 281ms/step - loss: 0.0559 - accuracy: 0.9803 - val_loss: 1.3597 - val_accuracy: 0.7172\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 176s 282ms/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 1.3970 - val_accuracy: 0.6420\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 176s 282ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 1.3560 - val_accuracy: 0.7044\n"
     ]
    }
   ],
   "source": [
    "rnn_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = rnn_model.fit(\n",
    "    train_data, \n",
    "    validation_data=valid_data, \n",
    "    epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, truncar as sequências para 100 tokens e usar uma camada `SimpleRNN` bidirecional resultou em **80%** de precisão de classificação. Embora a previsão seja um pouco menor quando comparada ao modelo *LSTM* bidirecional anterior (**85,15%** de precisão no conjunto de dados de teste), o desempenho nessas sequências truncadas é muito melhor do que o desempenho que poderíamos alcançar com um `SimpleRNN` em resenhas de filmes completos. Como exercício opcional, você pode verificar isso usando as duas funções auxiliares que já definimos. Experimente com `max_seq_length=None` e defina o argumento bidirecional dentro da função auxiliar `build_rnn_model()` como `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Projeto dois – modelagem de linguagem em nível de caractere no *TensorFlow***\n",
    "\n",
    "A modelagem de linguagem é uma aplicatição fascinante que permite que as máquinas executem tarefas relacionadas à linguagem humana, como gerar frases em inglês.\n",
    "\n",
    "No modelo que construiremos agora, a entrada é um documento de texto, e nosso objetivo é desenvolver um modelo que possa gerar um novo texto com estilo semelhante ao documento de entrada. Exemplos de tal entrada são um livro ou um programa de computador em uma linguagem de programação específica.\n",
    "\n",
    "Na modelagem de linguagem em nível de caractere, a entrada é dividida em uma sequência de caracteres que são inseridos em nossa rede, um caractere por vez. A rede processará cada novo personagem em conjunto com a memória dos personagens vistos anteriormente para prever o próximo. A figura a seguir mostra um exemplo de modelagem de linguagem em nível de caractere (observe que EOS significa *End of Sequence* (fim de sequência)):\n",
    "![](imagens\\modelagem_nivel_caractere.PNG)\n",
    "\n",
    "Podemos dividir essa implementação em três etapas separadas:\n",
    "1. preparar os dados, construir o modelo RNN e realizar previsão, e\n",
    "2. amostragem do próximo caractere para gerar novo texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento do conjunto de dados\n",
    "Nesta seção, prepararemos os dados para modelagem de linguagem em nível de caractere.\n",
    "\n",
    "Para obter os dados de entrada, visite o site do Project Gutenberg em https://www.gutenberg.org/, que fornece milhares de e-books gratuitos. Para o nosso exemplo, você pode baixar o livro A Ilha Misteriosa, de Júlio Verne (publicado em 1874) em formato de texto simples de http://www.gutenberg.org/files/1268/1268-0.txt.\n",
    "\n",
    "Depois de baixar o conjunto de dados, podemos lê-lo em uma sessão do Python como texto simples. Usando o código a seguir, vamos ler o texto diretamente do arquivo baixado e remover partes do início e do fim (estes contêm certas descrições do projeto Gutenberg). Em seguida, criaremos uma variável *Python*, `char_set`, que representa o conjunto de caracteres `unique` observados neste texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'https://www.gutenberg.org/files/1268/1268-0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willi\\OneDrive\\Documentos\\4. GitHub\\Machine_Learning_Studies\\Modelagem Sequencial usando RNN.ipynb Cell 49'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000048?line=2'>3</a>\u001b[0m \u001b[39m## Lendo o arquivo e processando o texto\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000048?line=3'>4</a>\u001b[0m arquivo \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://www.gutenberg.org/files/1268/1268-0.txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000048?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m (arquivo, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf8\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000048?line=6'>7</a>\u001b[0m     text \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/OneDrive/Documentos/4.%20GitHub/Machine_Learning_Studies/Modelagem%20Sequencial%20usando%20RNN.ipynb#ch0000048?line=8'>9</a>\u001b[0m start_indx \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mTHE MISTERIOUS ISLAND\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'https://www.gutenberg.org/files/1268/1268-0.txt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Lendo o arquivo e processando o texto\n",
    "arquivo = \"https://www.gutenberg.org/files/1268/1268-0.txt\"\n",
    "\n",
    "with open (arquivo, encoding='utf8') as fp:\n",
    "    text = fp.read()\n",
    "\n",
    "start_indx = text.find(\"THE MISTERIOUS ISLAND\")\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print(f\"Tamanho total: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finalizado. Arquivo salvo em: 1268-0.txt\n",
      "\n",
      "Tamanho total: 1112350\n",
      "Caracteres únicos: 80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "url = \"https://www.gutenberg.org/files/1268/1268-0.txt\"\n",
    "resposta = requests.get(url=url)\n",
    "endereco = os.path.basename(url.split('?')[0])\n",
    "if resposta.status_code == requests.codes.OK:\n",
    "    with open(endereco, 'wb') as arquivo:\n",
    "        arquivo.write(resposta.content)\n",
    "    print('Download finalizado. Arquivo salvo em: {}'.format(endereco))\n",
    "\n",
    "with open('1268-0.txt', 'r', encoding='utf8') as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "print()\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Tamanho total:', len(text))\n",
    "print('Caracteres únicos:', len(char_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o download e pré-processamento do texto, temos uma sequência composta por 1.112.350 caracteres no total e 80 caracteres únicos. No entanto, a maioria das bibliotecas NN e implementações RNN não podem lidar com dados de entrada em formato de *string*, e é por isso que temos que converter o texto em um formato numérico. Para fazer isso, vamos criar um dicionário Python simples que mapeia cada caractere para um inteiro, `char2int`. Também precisaremos de um mapeamento reverso para converter os resultados do nosso modelo de volta em texto.\n",
    "\n",
    "Embora o inverso possa ser feito usando um dicionário que associa chaves inteiras a valores de caracteres, usar um array *NumPy* e indexar o array para mapear índices para esses caracteres exclusivos é mais eficiente. A figura a seguir mostra um exemplo de conversão de caracteres em inteiros e o inverso para as palavras \"Hello\" e \"world\":\n",
    "\n",
    "![](imagens\\mapeamento_reverso.PNG)\n",
    "\n",
    "A construção do dicionário para mapear caracteres para inteiros e o mapeamento reverso por meio da indexação de um array *NumPy*, conforme mostrado na figura anterior, é a seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Encode Shape: (1112350,)\n",
      "THE MYSTERIOUS  == Encoding ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] == Reverse ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)                        # Organizando o Conjunto ÚNICO da dados\n",
    "char2int = {ch:i for i, ch in enumerate(chars_sorted)} # Criando os índices para o Conjunto organizado em um Dict\n",
    "char_array = np.array(chars_sorted)                    # Criando um Array com o Conjunto ordenado.\n",
    "\n",
    "text_encoded = np.array(                               # Aplicando o mapeamento no texto de Júlio Verne\n",
    "                        [char2int[ch] for ch in text],\n",
    "                        dtype=np.int32   \n",
    "                       )              \n",
    "print(f'Text Encode Shape: {text_encoded.shape}')       \n",
    "\n",
    "print(text[:15], '== Encoding ==>', text_encoded[:15]) # Aplicando o Encode nos primeiros 15 caracteres\n",
    "print(text_encoded[15:21], '== Reverse ==>',''.join(char_array[text_encoded[15:21]])) # Aplicando o decode no caracteres ISLAND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz NumPy `text_encoded` contém os valores codificados para todos os caracteres no texto. Agora, vamos criar um conjunto de dados do *TensorFlow* a partir deste array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 ===> T\n",
      "32 ===> H\n",
      "29 ===> E\n",
      "1 ===>  \n",
      "37 ===> M\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print(f'{ex.numpy()} ===> {char_array[ex.numpy()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até agora, criamos um objeto Dataset iterável para obter caracteres na ordem em que aparecem no texto. Agora, vamos dar um passo atrás e olhar para o quadro geral do que estamos tentando fazer. Para a tarefa de geração de texto, podemos formular o problema como uma tarefa de classificação.\n",
    "\n",
    "Suponha que tenhamos um conjunto de sequências de caracteres de texto incompletos, conforme mostrado na figura a seguir:\n",
    "\n",
    "![](imagens\\sequencias_targets.PNG)\n",
    "\n",
    "Na figura anterior, podemos considerar as sequências mostradas na caixa à esquerda como sendo a entrada. Para gerar um novo texto, nosso objetivo é projetar um modelo que possa prever o **próximo caractere** de uma determinada sequência de entrada, onde a sequência de entrada representa um texto incompleto. Por exemplo, depois de ver `\"Deep Learn\"`, o modelo deve prever `\"i\"` como o próximo caractere. Dado que temos 80 caracteres únicos, este problema torna-se uma tarefa de classificação multiclasse.\n",
    "\n",
    "Começando com uma sequência de comprimento 1 (ou seja, uma única letra), podemos gerar iterativamente novo texto com base nessa abordagem de classificação multiclasse, conforme ilustrado na figura a seguir:\n",
    "\n",
    "![](imagens\\sequencias_classificacao.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar a tarefa de geração de texto no *TensorFlow*, primeiro vamos cortar o comprimento da sequência para 40. Isso significa que o tensor de entrada, x, consiste em 40 tokens. **Na prática, o comprimento da sequência impacta na qualidade do texto gerado**. Sequências mais longas podem resultar em frases mais significativas. Para sequências mais curtas, no entanto, o modelo pode se concentrar em capturar palavras individuais corretamente, ignorando o contexto na maior parte.\n",
    "\n",
    "Embora sequências mais longas geralmente resultem em sentenças mais significativas, como mencionado, para sequências longas, o modelo RNN terá problemas para capturar dependências de longo prazo. Assim, na prática, encontrar um ponto ideal e um bom valor para o comprimento da sequência é um problema de otimização de hiperparâmetros, que temos que avaliar empiricamente. Aqui, vamos escolher 40, pois oferece uma boa troca.\n",
    "\n",
    "Como você pode ver na figura anterior, as entradas, $\\small \\textbf{x}$, e os destinos, $\\small \\textbf{y}$, são deslocados por um caractere. Assim, dividiremos o texto em pedaços de tamanho 41: os primeiros 40 caracteres formarão a sequência de entrada, $\\small \\textbf{x}$, e os últimos 40 elementos formarão a sequência alvo, $\\small \\textbf{y}$.\n",
    "\n",
    "Já armazenamos todo o texto codificado em sua ordem original em um objeto `Dataset`, `ds_text_encoded`. Usando as técnicas relativas à transformação de conjuntos de dados que já abordamos, você pode pensar em uma maneira de obter a entrada, $\\small \\textbf{x}$, e o destino, $\\small \\textbf{y}$, como foi mostrado na figura anterior? A resposta é muito simples: primeiro usaremos o método `batch()` para criar blocos de texto com 41 caracteres cada. Isso significa que definiremos `batch_size=41`. Vamos nos livrar ainda mais do último lote se for menor que 41 caracteres. Como resultado, o novo conjunto de dados fragmentado, denominado `ds_chunks`, sempre conterá sequências de tamanho 41. Os fragmentos de 41 caracteres serão usados ​​para construir a sequência $\\small \\textbf{x}$ (ou seja, a entrada), bem como a sequência $\\small \\textbf{y}$ (que é, o alvo), ambos terão 40 elementos. Por exemplo, a sequência x consistirá dos elementos com índices [0, 1,...,39]. Além disso, como a sequência $\\small \\textbf{y}$ será deslocada de uma posição em relação a $\\small \\textbf{x}$, seus índices correspondentes serão [1, 2,..., 40]. Em seguida, aplicaremos uma função de transformação usando o método `map()` para separar as sequências $\\small \\textbf{x}$ e $\\small \\textbf{y}$ de acordo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "ds_chuncks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "\n",
    "# Definir uma Função que divide X e Y\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "# Aplicar o map() em todo conjunto com a função\n",
    "\n",
    "ds_sequences = ds_chuncks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver alguns exemplos deste dataset transformado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input  (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "  Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      "  Input  (x): ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
      "  Target (y): 'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print(f\"  Input  (x): {repr(''.join(char_array[example[0].numpy()]))}\" )\n",
    "    print(f\"  Target (y): {repr(''.join(char_array[example[1].numpy()]))}\" )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, a última etapa na preparação do conjunto de dados é dividir esse conjunto de dados em minilotes. Durante a primeira etapa de pré-processamento para dividir o conjunto de dados em lotes, criamos pedaços de frases. Cada pedaço representa uma frase, que corresponde a um exemplo de treinamento. Agora, vamos embaralhar os exemplos de treinamento e dividir as entradas em mini-lotes novamente; no entanto, desta vez, cada lote conterá vários exemplos de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 40), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None, 40), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo um modelo RNN em nível de personagem\n",
    "Agora que o conjunto de dados está pronto, a construção do modelo será relativamente simples. Para reutilização de código, escreveremos uma função, `build_model`, que define um modelo RNN usando a classe Keras `Sequential`. Então, podemos especificar os parâmetros de treinamento e chamar essa função para obter um modelo RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 256)         20480     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 512)         1574912   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, None, 80)          41040     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,636,432\n",
      "Trainable params: 1,636,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(\n",
    "            rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size = charset_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a camada *LSTM* neste modelo tem o formato de saída (None, None, 512), o que significa que a saída de *LSTM* é de *rank* 3. A primeira dimensão representa o número de lotes, a segunda dimensão o comprimento da sequência de saída e a última dimensão corresponde ao número de unidades ocultas. A razão para ter a saída de *rank* 3 da camada *LSTM* é porque especificamos `return_sequences=True` ao definir nossa camada *LSTM*. Uma camada totalmente conectada (`Dense`) recebe a saída da célula *LSTM* e calcula os logits para cada elemento das sequências de saída. Como resultado, a saída final do modelo também será um tensor de *rank* 3.\n",
    "Além disso, especificamos `activation=None` para a camada final totalmente conectada. A razão para isso é que precisaremos ter os logits como saídas do modelo para que possamos amostrar as previsões do modelo para gerar um novo texto. Chegaremos a esta parte de amostragem mais tarde. Por enquanto, vamos treinar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "424/424 [==============================] - 13s 28ms/step - loss: 2.3232\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 12s 29ms/step - loss: 1.7520\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.5413\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.4213\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.3473\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.2971\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.2596\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.2296\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.2040\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.1827\n",
      "Epoch 11/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.1635\n",
      "Epoch 12/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.1464\n",
      "Epoch 13/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.1302\n",
      "Epoch 14/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.1149\n",
      "Epoch 15/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.1009\n",
      "Epoch 16/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.0867\n",
      "Epoch 17/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.0738\n",
      "Epoch 18/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.0611\n",
      "Epoch 19/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.0480\n",
      "Epoch 20/20\n",
      "424/424 [==============================] - 12s 28ms/step - loss: 1.0360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2893ae7bf40>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True\n",
    "    ))\n",
    "\n",
    "model.fit(ds, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos avaliar o modelo para gerar um novo texto, começando com uma determinada *string* curta. Na próxima seção, definiremos uma função para avaliar o modelo treinado.\n",
    "\n",
    "### Fase de avaliação – geração de novas passagens de texto\n",
    "\n",
    "O modelo RNN que treinamos na seção anterior retorna os logits de tamanho 80 para cada caractere único. Esses logits podem ser facilmente convertidos em probabilidades, por meio da função *softmax*, de que um determinado caractere seja encontrado como o próximo caractere. Para prever o próximo caractere na sequência, basta selecionar o elemento com o valor logit máximo, o que equivale a selecionar o caractere com maior probabilidade.\n",
    "\n",
    "No entanto, em vez de sempre selecionar o caractere com a maior probabilidade, **queremos amostrar (aleatoriamente) das saídas**; caso contrário, o modelo sempre produzirá **o mesmo texto**. O *TensorFlow* já fornece uma função, `tf.random.categorical()`, que podemos usar para extrair amostras aleatórias de uma distribuição categórica. Para ver como isso funciona, vamos gerar algumas amostras aleatórias de três categorias [0, 1, 2], com logits de entrada [1, 1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades: [0.33333334 0.33333334 0.33333334]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "\n",
    "print(f\"Probabilidades: {tf.math.softmax(logits=logits).numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1, 2, 0, 1, 0, 1, 1, 2, 1, 1]], dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "samples = tf.random.categorical(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode ver, com os logits dados, as categorias têm as mesmas probabilidades (ou seja, categorias equiprováveis). Portanto, se usarmos um tamanho de amostra grande ($\\small num\\_samples \\rightarrow \\infty)$, esperaríamos que o número de ocorrências de cada categoria chegasse a $\\small \\approx \\dfrac{1}{3}$ do tamanho da amostra. Se alterarmos os logits para [1, 1, 3], esperaríamos observar mais ocorrências para a categoria 2 (quando um número muito grande de exemplos é extraído dessa distribuição):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades: [0.10650698 0.10650698 0.78698605]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 3.0]]\n",
    "\n",
    "print(f\"Probabilidades: {tf.math.softmax(logits=logits).numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2, 2, 0, 2, 2, 2, 2, 2, 1, 2]], dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "samples = tf.random.categorical(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando `tf.random.categorical`, podemos gerar exemplos com base nos logits calculados pelo nosso modelo. Definimos uma função, `sample()`, que recebe uma *string* inicial curta, `starting_str`, e gera uma nova *string*, `generated_str`, que é inicialmente definida como a *string* de entrada. Em seguida, uma *string* de tamanho `max_input_length` é retirada do final de `generated_str` e codificada em uma sequência de inteiros, `encoded_input`. O `encoded_input` é passado para o modelo RNN para calcular os logits. Observe que a saída do modelo RNN é uma sequência de logits com o mesmo comprimento da sequência de entrada, pois especificamos `return_sequences=True` para a última camada recorrente de nosso modelo RNN. Portanto, cada elemento na saída do modelo RNN representa os logits (aqui, um vetor de tamanho 80, que é o número total de caracteres) para o próximo caractere após observar a sequência de entrada pelo modelo.\n",
    "\n",
    "Aqui, usamos apenas o último elemento dos logits de saída (ou seja, $\\small \\textbf{o}^{(T)}$ ), que é passado para a função `tf.random.categorical()` para gerar uma nova amostra. Essa nova amostra é convertida em um caractere, que é anexado ao final da *string* gerada, `generated_text`, aumentando seu comprimento em 1. Em seguida, esse processo é repetido, pegando o último número de caracteres `max_input_length` do final do `generated_str`, e usando isso para gerar um novo caractere até que o comprimento da *string* gerada atinja o valor desejado. O processo de consumir a sequência gerada como entrada para geração de novos elementos é chamado de `auto-regression` (**auto-regressão**).\n",
    "\n",
    "> #### Retornando sequências como saída\n",
    "> \n",
    "> Você pode se perguntar por que usamos `return_sequences=True` quando usamos apenas o último caractere para amostrar um novo caractere e ignoramos o restante da saída. Embora essa pergunta faça todo o sentido, você não deve esquecer que usamos toda a sequência de saída para treinamento. A perda é calculada com base em cada previsão na saída e não apenas na última.\n",
    "\n",
    "O código para a função `sample()` é o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str, \n",
    "           len_generated_text=500, \n",
    "           max_input_length=40,\n",
    "           scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "\n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_indx = tf.random.categorical(\n",
    "            scaled_logits, num_samples=1)\n",
    "        \n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n",
    "\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "        \n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        encoded_input = tf.concat(\n",
    "            [encoded_input, new_char_indx],\n",
    "            axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora gerar algum texto novo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was eggled from the passage of a power part. It was cleaning the\n",
      "rejoice, though but a good one of these plantagio, which they wished to go to sighter the animal, indergounacial bay, and\n",
      "capricious apparatus. Cyrus Harding\n",
      "thought\n",
      "of confinence had recies of the downs of the colonists, without finding again lors. Cyrus Harding bad\n",
      "of leavings which he sainful\n",
      "arrangements.”\n",
      "\n",
      "At seals chosen suddenly.\n",
      "\n",
      "The engineer’s head, and therefore, caused there without wishing. The time was scanty informed\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode ver, o modelo gera principalmente palavras corretas e, em alguns casos, as frases são **parcialmente significativas**. Você pode ajustar ainda mais os parâmetros de treinamento, como o comprimento das sequências de entrada para treinamento, a arquitetura do modelo e os parâmetros de amostragem (como `max_input_length`).\n",
    "\n",
    "Além disso, para controlar a previsibilidade das amostras geradas (ou seja, gerar texto seguindo os padrões aprendidos do texto de treinamento versus adicionar mais aleatoriedade), os logits calculados pelo modelo RNN podem ser dimensionados antes de serem passados para `tf.random.categorical()` para amostragem. O fator de escala, $\\small \\alpha$ , pode ser interpretado como o inverso da temperatura na física. Temperaturas mais altas resultam em mais aleatoriedade versus comportamento mais previsível em temperaturas mais baixas. Ao escalonar os logits com $\\small \\alpha < 1$, as probabilidades calculadas pela função `softmax` se tornam mais uniformes, conforme mostrado no código a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades antes de dimensionar:           [0.10650698 0.10650698 0.78698604]\n",
      "Probabilidades depois de dimensionar com 0.5:  [0.21194156 0.21194156 0.57611688]\n",
      "Probabilidades depois de dimensionar com 0.1:  [0.31042377 0.31042377 0.37915245]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([[1.0, 1.0, 3.0]])\n",
    "print(f\"Probabilidades antes de dimensionar:           {tf.math.softmax(logits).numpy()[0]}\")\n",
    "print(f\"Probabilidades depois de dimensionar com 0.5:  {tf.math.softmax(0.5*logits).numpy()[0]}\")\n",
    "print(f\"Probabilidades depois de dimensionar com 0.1:  {tf.math.softmax(0.1*logits).numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode ver, dimensionar os logits por $\\small \\alpha = 0.1$ resulta em probabilidades quase uniformes [0.31, 0.31, 0.38]. Agora, podemos comparar o texto gerado com $\\small \\alpha = 2.0$ e $\\small \\alpha = 0.5$, conforme mostrado nos seguintes pontos:\n",
    "\n",
    "* $\\small \\alpha = 2.0 \\rightarrow mais\\: previsível$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was again the stranger, and I say our ‘Bonadventure.”\n",
      "\n",
      "“Then the reporter was called the bank of the rock, and the brig had been a possible to start the state of the crater.\n",
      "\n",
      "“And you, Mr. Spilett, and these things were a few minutes the destruction of the grotto, and the settlers had the engineer and his companions left the stranger fell on the shore, and the reporter and the reporter and Pencroft, and you will be a good part of the volcano.”\n",
      "\n",
      "“Well, my boy, but at the same time against the co\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\small \\alpha = 0.5 \\rightarrow mais\\: aleatório$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island had egbly sleepliggt and the Happy, Herbert! ciff swelland,\n",
      "myrifrt-lumble,” then, tharked Cune--lan,.. Vade. he\n",
      "keb-darh tak;\n",
      "unforwing our Islan her a Farxisy neither sixaptific ode, or carbly voice at the verage cold Pencroft.\n",
      "\n",
      "occoppeded shallibre!”; terrishod and push, was\n",
      "already nized it in af excetill reliam lithudencuces,\n",
      "of quelusis,\n",
      "Cyrus Harding Awar and a frise massidy relun. Had Nabual:-illy oursquise, yem in any equal froster. Lay nwers-fall, with three. Would have sombling A9uri\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados mostram que dimensionar os logits com $\\small \\alpha = 0.5$ (aumentando a temperatura) gera mais texto aleatório. Há uma compensação entre a novidade do texto gerado e sua correção.\n",
    "\n",
    "Nesta seção, trabalhamos com geração de texto em nível de caractere, que é uma tarefa de modelagem de sequência a sequência (seq2seq). Embora este exemplo possa não ser muito útil por si só, é fácil pensar em várias aplicações úteis para esses tipos de modelos; por exemplo, um modelo RNN semelhante pode ser treinado como um *chatbot* para auxiliar os usuários com consultas simples."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1870f1194fb5b3d43b6d32e845741389586dbe9c4e1e45e17e0f6602cfe22778"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
