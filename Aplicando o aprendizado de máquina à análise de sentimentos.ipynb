{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Aplicando o aprendizado de máquina à análise de sentimentos</h1>\n",
    "\n",
    "<p align='center'><img src= https://cibersistemas.pt/wp-content/uploads/2020/09/wall-5.jpeg width='500'></p>\n",
    "\n",
    "\n",
    "Na era moderna da internet e das mídias sociais, as opiniões, avaliações e recomendações das pessoas se tornaram um recurso valioso para a ciência política e os negócios. Graças às tecnologias modernas, agora podemos coletar e analisar esses dados com mais eficiência. Neste capítulo, vamos nos aprofundar em um subcampo do processamento de linguagem natural (NLP) chamado análise de sentimentos e aprender a usar algoritmos de aprendizado de máquina para classificar documentos com base em sua polaridade: a atitude do escritor. Em particular, vamos trabalhar com um conjunto de dados de 50.000 críticas de filmes do Internet Movie Database (IMDb) e construir um preditor que possa distinguir entre críticas positivas e negativas.\n",
    "\n",
    "## Preparando os dados de revisão de filme do IMDb para processamento de texto\n",
    "Como mencionado, a análise de sentimentos, às vezes também chamada de **mineração de opinião**, é uma subdisciplina popular do campo mais amplo da *NLP*; preocupa-se em analisar a polaridade dos documentos. Uma tarefa popular na análise de sentimentos é a classificação de documentos com base nas opiniões ou emoções expressas dos autores em relação a um tópico específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% | 80 MB | 1.00 MB/s | 80 sec elapsed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "source = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "target = 'aclImdb_v1.tar.gz'\n",
    "\n",
    "\n",
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = progress_size / (1024.**2 * duration)\n",
    "    percent = count * block_size * 100. / total_size\n",
    "\n",
    "    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d sec elapsed\" %\n",
    "                    (percent, progress_size / (1024.**2), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "if not os.path.isdir('aclImdb') and not os.path.isfile('aclImdb_v1.tar.gz'):\n",
    "    urllib.request.urlretrieve(source, target, reporthook)\n",
    "\n",
    "# Extraindo os dados\n",
    "if not os.path.isdir('aclImdb'):\n",
    "\n",
    "    with tarfile.open(target, 'r:gz') as tar:\n",
    "        tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento do conjunto de dados do filme em um formato mais conveniente\n",
    "Tendo extraído com sucesso o conjunto de dados, agora reuniremos os documentos de texto individuais do arquivo de download descompactado em um único arquivo CSV.\n",
    "\n",
    "A seguir, leremos as resenhas de filmes em um objeto *DataFrame* do *pandas*, que pode levar até 10 minutos em um computador desktop padrão.\n",
    "Para visualizar o progresso e o tempo estimado até a conclusão, usaremos o pacote *Python Progress Indicator* (PyPrind, https://pypi.python.org/pypi/PyPrind/)que foi desenvolvido há vários anos para esses fins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:49\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# change the `basepath` to the directory of the\n",
    "# unzipped movie dataset\n",
    "\n",
    "basepath = 'aclImdb'\n",
    "\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "df = pd.DataFrame()\n",
    "for s in ('test', 'train'):\n",
    "    for l in ('pos', 'neg'):\n",
    "        path = os.path.join(basepath, s, l)\n",
    "        for file in sorted(os.listdir(path)):\n",
    "            with open(os.path.join(path, file), \n",
    "                      'r', encoding='utf-8') as infile:\n",
    "                txt = infile.read()\n",
    "            df = df.append([[txt, labels[l]]], \n",
    "                           ignore_index=True)\n",
    "            pbar.update()\n",
    "df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para nossa própria conveniência, também armazenaremos o \n",
    "# conjunto de dados de revisão de filme montado e embaralhado como um arquivo CSV:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "df.to_csv('movie_data.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8bbe703e4409461e5c1796f0c401e26e62f32801f1a5b19455b89c31c613fbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
