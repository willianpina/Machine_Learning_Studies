{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>Paralelizando o treinamento de rede neural com o TensorFlow</h1>\n",
    "<p align=center><img src=https://www.tensorflow.org/images/tf_logo_social.png?hl=pt-br width=500></p>\n",
    "\n",
    "O *TensorFlow* é uma das bibliotecas de aprendizado profundo mais populares atualmente disponíveis e nos permite implementar redes neurais (RN) com muito mais eficiência do que qualquer uma de nossas implementações NumPy anteriores. Agora, começaremos a usar o *TensorFlow* e veremos como ele traz benefícios significativos para o desempenho do treinamento.\n",
    "\n",
    "### *TensorFlow* e desempenho de treinamento\n",
    "O *TensorFlow* pode acelerar significativamente nossas tarefas de aprendizado de máquina. Para entender como ele pode fazer isso, vamos começar discutindo alguns dos desafios de desempenho que normalmente encontramos quando executamos cálculos caros em nosso hardware. Em seguida, analisaremos em alto nível o que é o *TensorFlow* e qual será nossa abordagem de aprendizado.\n",
    "\n",
    "### Como aprenderemos o *TensorFlow*\n",
    "Primeiro, abordaremos o modelo de programação do *TensorFlow*, em particular, a criação e manipulação de tensores. Em seguida, veremos como carregar dados e utilizar objetos *TensorFlow* Dataset, o que nos permitirá iterar por meio de um conjunto de dados de forma eficiente. Além disso, discutiremos os conjuntos de dados existentes e prontos para uso no submódulo `tensorflow_datasets` e aprenderemos como usá-los.\n",
    "\n",
    "Depois de aprender sobre esses conceitos básicos, a API `tf.keras` será introduzida e avançaremos para a construção de modelos de aprendizado de máquina, aprenderemos a compilar e treinar os modelos e aprenderemos a salvar os modelos treinados em disco para avaliação futura.\n",
    "\n",
    "### Primeiros passos com o *TensorFlow* \n",
    "\n",
    "Vamos dar os primeiros passos no uso da API *TensorFlow* de baixo nível. Depois de instalar o *TensorFlow*, abordaremos como criar tensores no *TensorFlow* e diferentes maneiras de manipulá-los, como alterar sua forma, tipo de dados e assim por diante.\n",
    "\n",
    "### Instalando o *TensorFlow*\n",
    "Dependendo de como seu sistema está configurado, normalmente você pode usar o instalador `pip` do *Python* e instalar o *TensorFlow* do *PyPI* executando o seguinte no seu terminal:\n",
    "\n",
    "`pip install tensorflow`\n",
    "\n",
    "Isso instalará a versão estável mais recente. Para garantir que o código apresentado neste capítulo possa ser executado conforme o esperado, é recomendável usar o *TensorFlow* 2.0.0, que pode ser instalado especificando a versão explicitamente:\n",
    "\n",
    "`pip install tensorflow==[versão desejada]`\n",
    "\n",
    "### Criando tensores no *TensorFlow*\n",
    "Agora, vamos considerar algumas maneiras diferentes de criar tensores e, em seguida, ver algumas de suas propriedades e como manipulá-las. Em primeiro lugar, podemos simplesmente criar um tensor de uma lista ou um array *NumPy* usando a função `tf.convert_to_tensor` da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "a = np.array([1,2,3], dtype=np.int32)\n",
    "b = [4,5,6]\n",
    "\n",
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso resultou nos tensores $\\small t_a$ e $\\small t_b$, com suas propriedades, `shape=(3,)` e `dtype=int32`, adotadas de sua fonte. Semelhante aos *arrays* *NumPy*, podemos ver ainda mais estas propriedades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones = tf.ones((2,3))\n",
    "t_ones.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter acesso aos valores aos quais um tensor se refere, podemos simplesmente chamar o método `.numpy()` em um tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, a criação de um tensor de valores constantes pode ser feita da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.2   5.    3.142], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "const_tensor = tf.constant([1.2,5, np.pi], dtype=tf.float32)\n",
    "\n",
    "print(const_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando o tipo de dados e a forma de um tensor\n",
    "Aprender maneiras de manipular tensores é necessário para torná-los compatíveis para entrada em um modelo ou operação. Agora, você aprenderá a manipular tipos e formas de dados de tensor por meio de várias funções do *TensorFlow* que convertem (`cast`), remodelam(`reshape`), transpõem(`transpose`) e compactam(`squeeze`).\n",
    "\n",
    "A função `tf.cast()` pode ser usada para alterar o tipo de dados de um tensor para um tipo desejado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "t_a_new = tf.cast(t_a, tf.int64)\n",
    "print(t_a_new.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você verá mais a frente, certas operações requerem que os tensores de entrada tenham um certo número de dimensões (ou seja, *rank*) associadas a um certo número de elementos (*shape*). Assim, podemos precisar alterar a forma de um tensor, adicionar uma nova dimensão ou espremer uma dimensão desnecessária. O *TensorFlow* fornece funções (ou operações) úteis para conseguir isso, como `tf.transpose()`, `tf.reshape()` e `tf.squeeze()`. Vejamos alguns exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpondo um tensor:\n",
      " (3, 5) ----> (5, 3) \n",
      "\n",
      "Remodelando um tensor:\n",
      " (30,) ---> (5, 6) \n",
      "\n",
      "Removendo as dimensões:\n",
      " (1, 2, 1, 4, 1) --->  (1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "# Transpondo um tensor\n",
    "t = tf.random.uniform(shape=(3,5))\n",
    "t_tr = tf.transpose(t)\n",
    "print(\"Transpondo um tensor:\\n\", t.shape, '---->', t_tr.shape,'\\n')\n",
    "\n",
    "# Remodelando um tensor (por exemplo, de um vetor 1D para uma matriz 2D)\n",
    "t = tf.zeros((30,))\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\n",
    "print(\"Remodelando um tensor:\\n\", t.shape,'--->', t_reshape.shape,\"\\n\")\n",
    "\n",
    "# Removendo as dimensões desnecessárias (dimensões que possuem tamanho 1, que não são necessárias):\n",
    "\n",
    "t = tf.zeros((1, 2, 1, 4, 1))\n",
    "t_sqz = tf.squeeze(t, axis=(2, 4))\n",
    "print(\"Removendo as dimensões:\\n\",t.shape, '---> ', t_sqz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando operações matemáticas a tensores\n",
    "A aplicação de operações matemáticas, em particular operações de álgebra linear, é necessária para construir a maioria dos modelos de aprendizado de máquina. Abordaremos algumas operações de álgebra linear amplamente usadas, como produto elemento a elemento, multiplicação de matrizes e cálculo da norma de um tensor. Primeiro, vamos instanciar dois tensores aleatórios, um com distribuição uniforme no intervalo [–1, 1) e outro com distribuição normal padrão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "t1  = tf.random.uniform(shape=(5,2), minval=-1.0, maxval=1.0)\n",
    "t2  = tf.random.normal(shape=(5,2), mean=0.0, stddev=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que $\\small t1$ e $\\small t2$ têm a mesma forma. Agora, para calcular o produto elemento a elemento de $\\small t1$ e $\\small t2$, podemos usar o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27  -0.874]\n",
      " [-0.017 -0.175]\n",
      " [-0.296 -0.139]\n",
      " [-0.727  0.135]\n",
      " [-0.401  0.004]]\n"
     ]
    }
   ],
   "source": [
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular a média, soma e desvio padrão ao longo de um determinado eixo (ou eixos), podemos usar `tf.math.reduce_mean()`, `tf.math.reduce_sum()` e `tf.math.reduce_std()`. Por exemplo, a média de cada coluna em $\\small t1$ pode ser calculada da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.09  0.207], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t4 = tf.math.reduce_mean(t1, axis=0)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O produto matriz-matriz entre $\\small t1$ e $\\small t2$ (ou seja, $\\small t_1 \\times t_2^T$ , onde o sobrescrito $\\small T$ é para transposição) pode ser calculado usando a função `tf.linalg.matmul()` da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.144  1.115 -0.87  -0.321  0.856]\n",
      " [ 0.248 -0.191  0.25  -0.064 -0.331]\n",
      " [-0.478  0.407 -0.436  0.022  0.527]\n",
      " [ 0.525 -0.234  0.741 -0.593 -1.194]\n",
      " [-0.099  0.26   0.125 -0.462 -0.396]]\n"
     ]
    }
   ],
   "source": [
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\n",
    "print(t5.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outro lado, o cálculo de $\\small t_1 \\times t_2^T$ é realizado pela transposição de $\\small t_1$, resultando em uma matriz de tamanho $\\small 2 \\times 2$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.711  0.302]\n",
      " [ 0.371 -1.049]]\n"
     ]
    }
   ],
   "source": [
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\n",
    "print(t6.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, a função `tf.norm()` é útil para calcular a normal $\\small L^p$ de um tensor. Por exemplo, podemos calcular a norma $\\small L^2$ de `t1` da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.046 0.293 0.504 0.96  0.383]\n"
     ]
    }
   ],
   "source": [
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "print(norm_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar se este trecho de código calcula a normal $L^2$ de `t1` corretamente, você pode comparar os resultados com a seguinte função NumPy: `np.sqrt(np.sum(np.square(t1), axis=1))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.046, 0.293, 0.504, 0.96 , 0.383], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.square(t1),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir, empilhar e concatenar tensores\n",
    "Abordaremos as operações do *TensorFlow* para dividir um tensor em vários tensores, ou o inverso: empilhar e concatenar vários tensores em um único.\n",
    "Suponha que temos um único tensor e queremos dividi-lo em dois ou mais tensores. Para isso, o *TensorFlow* fornece uma função  `tf.split()`, que divide um tensor de entrada em uma lista de tensores de tamanho igual.\n",
    "\n",
    "Podemos determinar o número desejado de divisões como um inteiro usando o argumento `num_or_size_splits` para dividir um tensor ao longo de uma dimensão desejada especificada pelo argumento do eixo. Neste caso, o tamanho total do tensor de entrada ao longo da dimensão especificada deve ser divisível pelo número desejado de divisões. Alternativamente, podemos fornecer os tamanhos desejados em uma lista. Vamos dar uma olhada em um exemplo de ambas as opções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292 0.643]\n"
     ]
    }
   ],
   "source": [
    "# Fornecendo o número de divisões (deve ser divisível):\n",
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((6,))\n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.165, 0.901], dtype=float32),\n",
       " array([0.631, 0.435], dtype=float32),\n",
       " array([0.292, 0.643], dtype=float32)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_splits = tf.split(t, num_or_size_splits=3)\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, um tensor de tamanho 6 foi dividido em uma lista de três tensores, cada um com tamanho 2.\n",
    "\n",
    "* Fornecendo os tamanhos de divisões diferentes:\n",
    "\n",
    "Alternativamente, em vez de definir o número de divisões, também podemos especificar os tamanhos dos tensores de saída diretamente. Aqui, estamos dividindo um tensor de tamanho 5 em tensores de tamanhos 3 e 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((5,))\n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.165, 0.901, 0.631], dtype=float32),\n",
       " array([0.435, 0.292], dtype=float32)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_splits = tf.split(t, num_or_size_splits=[3, 2])\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Às vezes, estamos trabalhando com vários tensores e precisamos concatená-los ou empilhá-los para criar um único tensor. Nesse caso, as funções do *TensorFlow*, como `tf.stack()` e `tf.concat()`, são úteis. Por exemplo, vamos criar um tensor $\\small 1D$, $\\small A$, contendo $1s$ com tamanho $\\small 3$ e um tensor $\\small 1D$, $\\small B$, contendo $0_s$ com tamanho $\\small 2$ e concatená-los em um tensor $\\small 1D$, $\\small C$, de tamanho $\\small 5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones((3,))\n",
    "B = tf.zeros((2,))\n",
    "C = tf.concat([A, B], axis=0)\n",
    "print(C.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se criarmos tensores $\\small 1D$ $\\small A$ e $\\small B$, ambos com tamanho $\\small 3$, podemos empilhá-los para formar um tensor $\\small 2D$, $\\small S$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones((3,))\n",
    "B = tf.zeros((3,))\n",
    "S = tf.stack([A, B], axis=1)\n",
    "print(S.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como criar pipelines de entrada usando tf.data – a API do conjunto de dados do *TensorFlow*\n",
    "Quando estamos treinando um modelo de Rede Neural Profunda, geralmente treinamos o modelo de forma incremental usando um algoritmo de otimização iterativo, como *Gradient Descend* estocástico.\n",
    "\n",
    "Conforme mencionado no início, a *API Keras* é um *wrapper* em torno do *TensorFlow* para a construção de modelos RN. A *API Keras* fornece um método, `.fit()`, para treinar os modelos. Nos casos em que o conjunto de dados de treinamento é muito pequeno e pode ser carregado como um tensor na memória, os modelos do *TensorFlow* (criados com a *API Keras*) podem usar diretamente esse tensor por meio do método `.fit()` para treinamento.\n",
    "\n",
    "Em casos de uso típico, no entanto, quando o conjunto de dados é muito grande para caber na memória do computador, precisaremos carregar os dados do dispositivo de armazenamento principal (por exemplo, o disco rígido ou unidade de estado sólido) em pedaços, ou seja, lote por lote (observe o uso do termo \"lote\" em vez de \"mini-lote\" para ficar próximo da terminologia do *TensorFlow*). Além disso, podemos precisar construir um *pipeline* de processamento de dados para aplicar certas transformações e etapas de pré-processamento aos nossos dados, como centralização média, dimensionamento ou adição de ruído para aumentar o procedimento de treinamento e evitar *overfitting*.\n",
    "\n",
    "Aplicar funções de pré-processamento manualmente todas as vezes pode ser bastante complicado. Felizmente, o *TensorFlow* oferece uma classe especial para construir *pipelines* de pré-processamento eficientes e convenientes. Veremos uma visão geral dos diferentes métodos para construir um `Dataset` do *TensorFlow*, incluindo transformações de conjuntos de dados e etapas comuns de pré-processamento.\n",
    "\n",
    "### Como criar um conjunto de dados do *TensorFlow* a partir de tensores existentes\n",
    "Se os dados já existirem na forma de um objeto tensor, uma lista *Python* ou uma matriz *NumPy*, podemos criar facilmente um conjunto de dados usando a função `tf.data.Dataset.from_tensor_slices()`. Essa função retorna um objeto da classe `Dataset`, que podemos usar para iterar pelos elementos individuais no conjunto de dados de entrada. Como um exemplo simples, considere o código a seguir, que cria um conjunto de dados a partir de uma lista de valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.float32>\n",
      "\n",
      "**************************************************\n",
      "\n",
      "tf.Tensor(1.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0] # Lista de dados para consumo como tensor\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\n",
    "print(ds)\n",
    "print(\"\\n**************************************************\\n\")\n",
    "\n",
    "# Podemos facilmente iterar item a item neste conjunto de dados.\n",
    "for item in ds:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quisermos criar lotes a partir desse conjunto de dados, com um tamanho de lote desejado de 3, podemos fazer isso da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: [1.2 3.4 7.5]\n",
      "Batch 2: [4.1 5.  1. ]\n"
     ]
    }
   ],
   "source": [
    "ds_batch = ds.batch(3)\n",
    "for i, elem in enumerate(ds_batch,1):\n",
    "    print(f'Batch {i}: {elem.numpy()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso criará dois lotes desse conjunto de dados, onde os três primeiros elementos vão para o *lote 1* e os elementos restantes vão para o *lote 2*. O método .`batch()` tem um argumento opcional, `drop_remainder`, que é útil para casos em que o número de elementos no tensor não é divisível pelo tamanho do lote desejado. O padrão para `drop_remainder` é `False`. Veremos mais exemplos que ilustram o comportamento desse método posteriormente na subseção *Shuffle*, *batch* e *repeat*.\n",
    "\n",
    "### Combinando dois tensores em um conjunto de dados conjunto\n",
    "Muitas vezes, podemos ter os dados em dois (ou possivelmente mais) tensores. Por exemplo, poderíamos ter um tensor para as *features* e um tensor para os *labels*. Nesses casos, precisamos construir um conjunto de dados que combine esses tensores, o que nos permitirá recuperar os elementos desses tensores em tuplas.\n",
    "\n",
    "Suponha que temos dois tensores, $t_x$ e $t_y$. O tensor $t_x$ contém nossos valores de recursos, cada um de tamanho $\\small 3$, e $t_y$ armazena os rótulos de classe. Para este exemplo, primeiro criamos esses dois tensores da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "t_x = tf.random.uniform([4, 3], dtype=tf.float32)\n",
    "t_y = tf.range(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]\n",
      " [0.605 0.637 0.614]], shape=(4, 3), dtype=float32)\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(t_x)\n",
    "print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "print(t_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, queremos criar um conjunto de dados conjunto desses dois tensores. Observe que há uma correspondência *um-para-um* necessária entre os elementos desses dois tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [0.165 0.901 0.631]  y: 0\n",
      " x: [0.435 0.292 0.643]  y: 1\n",
      " x: [0.976 0.435 0.66 ]  y: 2\n",
      " x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)\n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "\n",
    "for example in ds_joint:\n",
    "    print(' x:', example[0].numpy(),\n",
    "    ' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, primeiro criamos dois conjuntos de dados separados, chamados *ds_x* e *ds_y*. Em seguida, usamos a função `zip` para formar um conjunto de dados conjunto. Alternativamente, podemos criar o conjunto de dados conjunto usando `tf.data.Dataset.from_tensor_slices()` da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [0.165 0.901 0.631]  y: 0\n",
      " x: [0.435 0.292 0.643]  y: 1\n",
      " x: [0.976 0.435 0.66 ]  y: 2\n",
      " x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_joint = tf.data.Dataset.from_tensor_slices((t_x, t_y)) # Passando uma tupla de valores\n",
    "\n",
    "for example in ds_joint:\n",
    "    print(' x:', example[0].numpy(),\n",
    "    ' y:', example[1].numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que uma fonte comum de erro pode ser que a correspondência em elementos entre os recursos originais ($\\small x$) e os rótulos ($\\small y$) pode ser perdida (por exemplo, se os dois conjuntos de dados forem embaralhados separadamente). No entanto, uma vez que eles são mesclados em um conjunto de dados, é seguro aplicar essas operações.\n",
    "\n",
    "A seguir, veremos como aplicar transformações a cada elemento individual de um conjunto de dados. Para isso, usaremos o conjunto de dados *ds_joint* anterior e aplicaremos o dimensionamento de recursos para dimensionar os valores para o intervalo [-1, 1), pois atualmente os valores de *t_x* estão no intervalo [0, 1) com base em uma distribuição uniforme aleatória :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[-0.67   0.803  0.262]   y: 0\n",
      "x:[-0.131 -0.416  0.285]   y: 1\n",
      "x:[ 0.952 -0.13   0.32 ]   y: 2\n",
      "x:[0.21  0.273 0.229]   y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_trans = ds_joint.map(lambda x, y: (x*2-1.0, y))\n",
    "for example in ds_trans:\n",
    "    print(f\"x:{example[0].numpy()}   y: {example[1].numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A aplicação desse tipo de transformação pode ser usada para uma função definida pelo usuário. Por exemplo, se tivermos um conjunto de dados criado a partir da lista de nomes de arquivos de imagem no disco, podemos definir uma função para carregar as imagens desses nomes de arquivos e aplicar essa função chamando o método `.map()`. Você verá um exemplo de aplicação de várias transformações a um conjunto de dados posteriormente.\n",
    "\n",
    "### Embaralhar, agrupar e repetir (*Shuffle*, *batch*, and *repeat*)\n",
    "Para treinar um modelo RN usando otimização estocástica de *gradient descent*, é importante alimentar os dados de treinamento como lotes embaralhados aleatoriamente. Você já viu como criar lotes chamando o método `.batch()` de um objeto de conjunto de dados. Agora, além de criar lotes, você verá como embaralhar e reiterar os conjuntos de dados. Continuaremos trabalhando com o conjunto de dados *ds_joint* anterior. Primeiro, vamos criar uma versão embaralhada do conjunto de dados *ds_joint*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x:  [0.976 0.435 0.66 ]   y:  2\n",
      "  x:  [0.435 0.292 0.643]   y:  1\n",
      "  x:  [0.165 0.901 0.631]   y:  0\n",
      "  x:  [0.605 0.637 0.614]   y:  3\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(buffer_size=len(t_x))\n",
    "\n",
    "for example in ds:\n",
    "    print('  x: ', example[0].numpy(), \n",
    "          '  y: ', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde as linhas são embaralhadas sem perder a correspondência *one-to-one* entre as entradas em $\\small x$ e $\\small y$. O método `.shuffle()` requer um argumento chamado `buffer_size`, que determina quantos elementos no conjunto de dados são agrupados antes de embaralhar. Os elementos no *buffer* são recuperados aleatoriamente e seu lugar no *buffer* é dado aos próximos elementos no conjunto de dados original (não embaralhado). Portanto, se escolhermos um *buffer_size* pequeno, podemos não embaralhar o conjunto de dados perfeitamente.\n",
    "\n",
    "Se o conjunto de dados for pequeno, escolher um *buffer_size* relativamente pequeno pode afetar **negativamente** o desempenho preditivo da RN, pois o conjunto de dados pode não ser completamente aleatório. Na prática, não tem um efeito perceptível ao trabalhar com conjuntos de dados relativamente grandes, o que é comum em aprendizado profundo. Alternativamente, para garantir a randomização completa durante cada época, podemos simplesmente escolher um tamanho de *buffer* que seja igual ao número de exemplos de treinamento, como no código anterior (`buffer_size=len(t_x)`).\n",
    "\n",
    "Você deve se lembrar de que dividir um conjunto de dados em lotes para treinamento de modelo é feito chamando o método `.batch()`. Agora, vamos criar esses lotes a partir do conjunto de dados *ds_joint* e dar uma olhada na aparência de um lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-x: \n",
      " [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]]\n",
      "\n",
      "Batch-y:    [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(batch_size=3,\n",
    "                    drop_remainder=False)\n",
    "\n",
    "batch_x, batch_y = next(iter(ds))\n",
    "\n",
    "print('Batch-x: \\n', batch_x.numpy())\n",
    "\n",
    "print('\\nBatch-y:   ', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, ao treinar um modelo para várias épocas, precisamos embaralhar e iterar o conjunto de dados pelo número desejado de épocas. Então, vamos repetir o conjunto de dados em lote duas vezes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (1, 3) [3]\n",
      "2 (3, 3) [0 1 2]\n",
      "3 (1, 3) [3]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(3).repeat(count=2)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso resulta em duas cópias de cada lote. Se alterarmos a ordem dessas duas operações, ou seja, primeiro lote e depois repetir, os resultados serão diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (3, 3) [3 0 1]\n",
      "2 (2, 3) [2 3]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.repeat(count=2).batch(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe a diferença entre os lotes. Quando fazemos o primeiro lote e depois repetimos, obtemos quatro lotes. Por outro lado, quando a repetição é realizada primeiro, três lotes são criados. Finalmente, para entender melhor como essas três operações (*batch, shuffle e repeat*) se comportam, vamos experimentá-las em ordens diferentes. Primeiro, vamos combinar as operações na seguinte ordem:  (1) *shuffle*, (2) *batch*, and (3) *repeat*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [2 1]\n",
      "1 (2, 3) [0 3]\n",
      "2 (2, 3) [0 3]\n",
      "3 (2, 3) [1 2]\n",
      "4 (2, 3) [3 0]\n",
      "5 (2, 3) [1 2]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 1: shuffle -> batch -> repeat\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [0 1]\n",
      "1 (2, 3) [2 3]\n",
      "2 (2, 3) [0 1]\n",
      "3 (2, 3) [2 3]\n",
      "4 (2, 3) [2 3]\n",
      "5 (2, 3) [0 1]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 2: batch -> shuffle -> repeat\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [0 1]\n",
      "1 (2, 3) [0 1]\n",
      "2 (2, 3) [2 3]\n",
      "3 (2, 3) [2 3]\n",
      "4 (2, 3) [0 1]\n",
      "5 (2, 3) [2 3]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 3: batch -> repeat -> shuffle\n",
    "ds = ds_joint.batch(2).repeat(3).shuffle(4)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enquanto o primeiro exemplo de código (*shuffle, batch, repeat*) parece ter embaralhado o conjunto de dados conforme o esperado, podemos ver que no segundo caso (*batch, shuffle, repeat*), os elementos dentro de um lote **não** foram embaralhados. Podemos observar essa falta de embaralhamento examinando mais de perto o tensor que contém os valores alvo, $\\small y$. Todos os lotes contêm o par de valores `[y=0, y=1]` ou o par de valores restante `[y=2, y=3]`; não observamos as outras permutações possíveis: `[y=2, y=0]`, `[y=1, y=3]`, e assim por diante.\n",
    "Observe que, para garantir que esses resultados não sejam coincidentes, você pode repetir isso com um número maior que 3. Por exemplo, tente com `.repeat(20)`.\n",
    "\n",
    "> Uma fonte comum de erro é chamar `.batch()` duas vezes seguidas em um determinado conjunto de dados. Ao fazer isso, recuperar itens do conjunto de dados resultante criará um lote de lotes de exemplos. Basicamente, cada vez que você chama `.batch()` em um conjunto de dados, ele aumenta a classificação dos tensores recuperados em um.\n",
    "\n",
    "## Criando um conjunto de dados de arquivos em seu disco de armazenamento local\n",
    "\n",
    "Construiremos um conjunto de dados a partir de arquivos de imagem armazenados em disco, a partir de arquivos armazenados. Para isso, usaremos dois módulos adicionais no TensorFlow: `tf.io` para ler o conteúdo do arquivo de imagem e `tf.image` para decodificar o conteúdo bruto e redimensionar a imagem.\n",
    "\n",
    "Antes de começarmos, vamos dar uma olhada no conteúdo desses arquivos. Usaremos a biblioteca `pathlib` para gerar uma lista de arquivos de imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "imgdir_path = pathlib.Path('cat_dog_images')\n",
    "\n",
    "file_list = sorted([str(path) for path in imgdir_path.glob('*.jpg')])\n",
    "\n",
    "print(file_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c198a0bf143da720db8a1ed2fdc43342371f98b364fdf2ef3c0c72d17a471d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
