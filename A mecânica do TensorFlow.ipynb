{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>Indo mais fundo – A mecânica do TensorFlow</h1>\n",
    "<p align=center><img src=https://cdn.shortpixel.ai/spai/w_912+q_+ret_img+to_webp/https://iaexpert.academy/wp-content/uploads/2021/01/26.01.png width = 500></p>\n",
    "\n",
    "Agora que temos alguma experiência prática com treinamento de uma Rede Neural (RN) do *TensorFlow* e aprendizado de máquina, é hora de mergulhar mais fundo na biblioteca do *TensorFlow* e explorar seu rico conjunto de recursos, o que nos permitirá implementar um aprendizado profundo mais avançado modelos nas próximas etapas.\n",
    "\n",
    "Usaremos diferentes aspectos da API do *TensorFlow* para implementar as RNs. Em particular, usaremos novamente a API *Keras*, que fornece várias camadas de abstração para tornar a implementação de arquiteturas padrão muito conveniente. O *TensorFlow* também nos permite implementar camadas RNs personalizadas, o que é muito útil em projetos orientados à pesquisa que exigem mais personalização. Mais adiante, implementaremos essa camada personalizada.\n",
    "\n",
    "Para ilustrar as diferentes formas de construção de modelos usando a API *Keras*, também consideraremos o problema clássico **exclusivo ou (XOR)**. Primeiramente, construiremos perceptrons multicamadas usando a classe `Sequential`. Em seguida, consideraremos outros métodos, como subclassificar `tf.keras.Model` para definir camadas personalizadas. Por fim, abordaremos o `tf.estimator`, uma API *TensorFlow* de alto nível que encapsula as etapas de aprendizado de máquina da entrada bruta à previsão.\n",
    "\n",
    "### Como criar um gráfico no *TensorFlow* v1.x\n",
    "Na versão anterior da API de baixo nível do *TensorFlow* (v1.x), esse gráfico precisava ser declarado explicitamente. As etapas individuais para criar, compilar e avaliar esse gráfico de computação no *TensorFlow* v1.x são as seguintes:\n",
    "1. Instanciar um novo gráfico de computação vazio\n",
    "2. Adicione nós (tensores e operações) ao gráfico de computação\n",
    "3. Avalie (execute) o gráfico:\n",
    "* Iniciar uma nova sessão\n",
    "* Inicialize as variáveis ​​no gráfico\n",
    "* Execute o gráfico de computação nesta sessão\n",
    "\n",
    "Antes de darmos uma olhada na abordagem dinâmica no *TensorFlow* v2, vamos ver um exemplo simples que ilustra como criar um gráfico no *TensorFlow* v1.x para calcular $\\small z = 2 \\times (a-b) + c$. As variáveis $​​\\small a$, $​​\\small b$ e $​​\\small c$ são escalares (números únicos) e definimos como constantes do *TensorFlow*. Um gráfico pode então ser criado chamando `tf.Graph()`. As variáveis, assim como os cálculos, representam os nós do gráfico, que definiremos da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF v1.x style\n",
    "import tensorflow as tf\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b')\n",
    "    c = tf.constant(3, name='c')\n",
    "    z = 2*(a-b) + c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste código, primeiro definimos o gráfico `g` via `g=tf.Graph()`. Em seguida, adicionamos nós ao gráfico, `g`, usando com `g.as_default()`. No entanto, observe que, se não criarmos um gráfico explicitamente, sempre haverá um gráfico padrão ao qual variáveis ​​e cálculos serão adicionados automaticamente.\n",
    "\n",
    "No *TensorFlow* v1.x, uma sessão é um ambiente no qual as operações e os tensores de um gráfico podem ser executados. A classe `Session` foi removida do *TensorFlow* v2; No entanto, por enquanto, ele ainda está disponível por meio do submódulo `tf.compat` para permitir a compatibilidade com o *TensorFlow* v1.x. Um objeto de sessão pode ser criado chamando `tf.compat.v1.Session()`, que pode receber um gráfico existente (no caso, `g`) como argumento, como em `Session(graph=g)`.\n",
    "\n",
    "Após lançar um gráfico em uma sessão do *TensorFlow*, podemos executar seus nós, ou seja, avaliar seus tensores ou executar seus operadores. Avaliar cada tensor individual envolve chamar seu método `eval()` dentro da sessão atual. Ao avaliar um tensor específico no gráfico, o *TensorFlow* precisa executar todos os nós anteriores no gráfico até atingir o nó de interesse fornecido. Caso haja uma ou mais variáveis *​​placeholder*, também precisamos fornecer valores para elas através do método `run` da sessão, como veremos mais adiante.\n",
    "\n",
    "Depois de definir o gráfico estático no trecho de código anterior, podemos executar o gráfico em uma sessão do *TensorFlow* e avaliar o tensor, `z`, da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: z =  1\n"
     ]
    }
   ],
   "source": [
    "## TF v1.x style\n",
    "\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    print('Result: z = ', sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como migrar um gráfico para o *TensorFlow* v2\n",
    "\n",
    "Em seguida, vamos ver como esse código pode ser migrado para o *TensorFlow* v2. O *TensorFlow* v2 usa gráficos dinâmicos (em oposição aos estáticos) por padrão (isso também é chamado de execução antecipada no *TensorFlow*), o que nos permite avaliar uma operação em tempo real. Portanto, não precisamos criar explicitamente um gráfico e uma sessão, o que torna o fluxo de trabalho de desenvolvimento muito mais conveniente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: z =  1\n"
     ]
    }
   ],
   "source": [
    "## TF v2 Style\n",
    "a = tf.constant(1, name='a')\n",
    "b = tf.constant(2, name='b')\n",
    "c = tf.constant(3, name='c')\n",
    "\n",
    "z = 2*(a - b) + c\n",
    "\n",
    "tf.print('Result: z = ', z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dados de entrada em um modelo: estilo *TensorFlow* v1.x\n",
    "\n",
    "Outra melhoria importante do *TensorFlow* v1.x para v2 diz respeito a como os dados podem ser carregados em nossos modelos. No *TensorFlow* v2, podemos alimentar dados diretamente na forma de variáveis *Python* ou arrays *NumPy*. No entanto, ao usar a API de baixo nível do *TensorFlow* v1.x, tivemos que criar variáveis de espaço reservado para fornecer dados de entrada a um modelo. Para o exemplo de gráfico de computação simples anterior, $\\small z = 2 \\times (a-b) + c$, vamos supor que `a`, `b` e `c` são os tensores de entrada de *Rank* 0. Podemos então definir três espaços reservados, que usaremos para \"feed\" dados para o modelo por meio de um dicionário *feed_dict*, da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: z = 1\n"
     ]
    }
   ],
   "source": [
    "## TF-v1.x style\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    a = tf.compat.v1.placeholder(shape=None, dtype=tf.int32, name='tf_a')\n",
    "    b = tf.compat.v1.placeholder(shape=None, dtype=tf.int32, name='tf_b')\n",
    "    c = tf.compat.v1.placeholder(shape=None, dtype=tf.int32, name='tf_c')\n",
    "    z = 2*(a - b) + c\n",
    "    \n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    feed_dict = {a:1, b:2, c:3}\n",
    "    print('Result: z =', sess.run(z, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dados de entrada em um modelo: estilo *TensorFlow* v2\n",
    "\n",
    "No *TensorFlow* v2, tudo isso pode ser feito simplesmente definindo uma função *Python* regular com `a`, `b` e `c` como seus argumentos de entrada, por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-v2 style\n",
    "def compute_z(a, b, c):\n",
    "    r1 = tf.subtract(a, b)\n",
    "    r2 = tf.multiply(2, r1)\n",
    "    z = tf.add(r2, c)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, para realizar o cálculo, podemos simplesmente chamar essa função com objetos `Tensor` como argumentos de função. Observe que as funções do *TensorFlow*, como `add`, `subtract` e `multiply`, também nos permitem fornecer entradas de classificações mais altas na forma de um objeto *TensorFlow* `Tensor`, um array *NumPy* ou possivelmente outros objetos *Python*, como listas e tuplas. No exemplo de código a seguir, fornecemos entradas escalares (*Rank* 0), bem como entradas de *Rank* 1 e *Rank* 2, como listas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar Inputs: 1\n",
      "Rank 1 Inputs: [1]\n",
      "Rank 2 Inputs: [[1]]\n"
     ]
    }
   ],
   "source": [
    "tf.print('Scalar Inputs:', compute_z(1, 2, 3))\n",
    "tf.print('Rank 1 Inputs:', compute_z([1], [2], [3]))\n",
    "tf.print('Rank 2 Inputs:', compute_z([[1]], [[2]], [[3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhorando o desempenho computacional com decoradores de função\n",
    "\n",
    "Como você viu na seção anterior, podemos escrever facilmente uma função *Python* normal e utilizar as operações do *TensorFlow*. No entanto, os cálculos por meio do modo de execução antecipada (gráfico dinâmico) não são tão eficientes quanto a execução de gráfico estático no *TensorFlow* v1.x. Assim, o *TensorFlow* v2 fornece uma ferramenta chamada **AutoGraph** que pode transformar automaticamente o código *Python* no código gráfico do *TensorFlow* para uma execução mais rápida. Além disso, o *TensorFlow* fornece um mecanismo simples para compilar uma função *Python* normal em um gráfico estático do *TensorFlow* para tornar os cálculos mais eficientes.\n",
    "\n",
    "Para ver como isso funciona na prática, vamos trabalhar com nossa função `compute_z` anterior e anotá-la para compilação de gráfico usando o decorador `@tf.function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_z(a, b, c):\n",
    "    r1 = tf.subtract(a, b)\n",
    "    r2 = tf.multiply(2, r1)\n",
    "    z = tf.add(r2, c)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que podemos usar e chamar essa função da mesma maneira que antes, mas agora o *TensorFlow* construirá um gráfico estático com base nos argumentos de entrada. *Python* suporta tipagem dinâmica e polimorfismo, então podemos definir uma função como `def f(a, b): return a+b` e chame-a usando entradas de *inteiro*, *float*, *list* ou *string* (lembre-se de que `a+b` é um valor válido operação para listas e *strings*). Embora os gráficos do *TensorFlow* exijam tipos e formas estáticos, o `tf.function` oferece suporte a esse recurso de digitação dinâmica. Por exemplo, vamos chamar esta função com as seguintes entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar Inputs: 1\n",
      "Rank 1 Inputs: [1]\n",
      "Rank 2 Inputs: [[1]]\n"
     ]
    }
   ],
   "source": [
    "tf.print('Scalar Inputs:', compute_z(1, 2, 3))\n",
    "tf.print('Rank 1 Inputs:', compute_z([1], [2], [3]))\n",
    "tf.print('Rank 2 Inputs:', compute_z([[1]], [[2]], [[3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que foi produzido as mesmas saídas de antes. Aqui, o *TensorFlow* usa um mecanismo de rastreamento para construir um gráfico com base nos argumentos de entrada. Para esse mecanismo de rastreamento, o *TensorFlow* gera uma tupla de chaves com base nas assinaturas de entrada fornecidas para chamar a função. As chaves geradas são as seguintes:\n",
    "\n",
    "* Para argumentos `tf.Tensor`, a chave é baseada em seus *shapes* e *dtypes*.\n",
    "* Para tipos *Python*, como listas, seu `id()` é usado para gerar chaves de cache.\n",
    "* Para valores primitivos do *Python*, as chaves de cache são baseadas nos valores de entrada.\n",
    "\n",
    "Ao chamar essa função decorada, o *TensorFlow* verificará se um gráfico com a chave correspondente já foi gerado. Se esse gráfico não existir, o *TensorFlow* gerará um novo gráfico e armazenará a nova chave. Por outro lado, se quisermos limitar a forma como uma função pode ser chamada, podemos especificar sua assinatura de entrada por meio de uma tupla de objetos `tf.TensorSpec` ao definir a função. Por exemplo, vamos redefinir a função anterior, `compute_z`, e especificar que apenas tensores de rank 1 do tipo `tf.int32` são permitidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),\n",
    "                              tf.TensorSpec(shape=[None], dtype=tf.int32),\n",
    "                              tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
    "def compute_z(a, b, c):\n",
    "    r1 = tf.subtract(a, b)\n",
    "    r2 = tf.multiply(2, r1)\n",
    "    z = tf.add(r2, c)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos chamar esta função usando tensores de rank 1 (ou listas que podem ser convertidas em tensores de rank 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 Inputs: [1]\n",
      "Rank 1 Inputs: [1 2]\n"
     ]
    }
   ],
   "source": [
    "tf.print('Rank 1 Inputs:', compute_z([1], [2], [3]))\n",
    "tf.print('Rank 1 Inputs:', compute_z([1, 2], [2, 4], [3, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, chamar essa função usando tensores com classificações diferentes de 1 resultará em um erro, pois a classificação não corresponderá à assinatura de entrada especificada, conforme a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Python inputs incompatible with input_signature:\n  inputs: (\n    1,\n    2,\n    3)\n  input_signature: (\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11580/184671221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Rank 0 Inputs:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_convert_inputs_to_signature\u001b[1;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[0;32m   2980\u001b[0m       \u001b[0mflat_input_signature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m       flatten_inputs)):\n\u001b[1;32m-> 2982\u001b[1;33m     raise ValueError(\"Python inputs incompatible with input_signature:\\n\"\n\u001b[0m\u001b[0;32m   2983\u001b[0m                      f\"{format_error_message(inputs, input_signature)}.\")\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Python inputs incompatible with input_signature:\n  inputs: (\n    1,\n    2,\n    3)\n  input_signature: (\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None))."
     ]
    }
   ],
   "source": [
    "tf.print('Rank 0 Inputs:', compute_z(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Python inputs incompatible with input_signature:\n  inputs: (\n    [[1], [2]],\n    [[2], [4]],\n    [[3], [6]])\n  input_signature: (\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11580/2431627549.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Rank 2 Inputs:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_convert_inputs_to_signature\u001b[1;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[0;32m   2980\u001b[0m       \u001b[0mflat_input_signature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m       flatten_inputs)):\n\u001b[1;32m-> 2982\u001b[1;33m     raise ValueError(\"Python inputs incompatible with input_signature:\\n\"\n\u001b[0m\u001b[0;32m   2983\u001b[0m                      f\"{format_error_message(inputs, input_signature)}.\")\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Python inputs incompatible with input_signature:\n  inputs: (\n    [[1], [2]],\n    [[2], [4]],\n    [[3], [6]])\n  input_signature: (\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n    TensorSpec(shape=(None,), dtype=tf.int32, name=None))."
     ]
    }
   ],
   "source": [
    "tf.print('Rank 2 Inputs:', compute_z([[1], [2]], [[2], [4]], [[3], [6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetos variáveis do *TensorFlow* para armazenar e atualizar os parâmetros do modelo\n",
    "\n",
    "No contexto do *TensorFlow*, uma `Variable` é um objeto Tensor especial que nos permite armazenar e atualizar os parâmetros de nossos modelos durante o treinamento. Um `Variable` pode ser criada apenas chamando a classe `tf.Variable` em valores iniciais especificados pelo usuário. No código a seguir, vamos gerar objetos `Variable` do tipo `float32`, `int32`, `bool` e `string`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var_a:0' shape=() dtype=float32, numpy=3.14>\n",
      "<tf.Variable 'var_b:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3])>\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=bool, numpy=array([ True, False])>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=string, numpy=array([b'abc'], dtype=object)>\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(initial_value=3.14, name='var_a')\n",
    "b = tf.Variable(initial_value=[1, 2, 3], name='var_b')\n",
    "c = tf.Variable(initial_value=[True, False], dtype=tf.bool)\n",
    "d = tf.Variable(initial_value=['abc'], dtype=tf.string)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que sempre temos que fornecer os valores iniciais ao criar um `Variable`. As variáveis têm um atributo chamado `treinable`, que, por padrão, é definido como `True`. APIs de nível superior, como *Keras*, usarão esse atributo para gerenciar as variáveis treináveis e não treináveis. Você pode definir um `Variable` não treinável da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([1,2,3], trainable=False)\n",
    "\n",
    "print(w.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores de um `Variable` podem ser modificados de forma eficiente executando algumas operações como `.assign()`, `.assign_add()` e métodos relacionados. Vejamos alguns exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'UnreadVariable' shape=(3,) dtype=int32, numpy=array([3, 1, 4])>\n"
     ]
    }
   ],
   "source": [
    "print(w.assign([3,1,4], read_value=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 0 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "w.assign_add([2,-1,2], read_value=False)\n",
    "\n",
    "print(w.value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando o argumento `read_value` estiver definido como `True` (que também é o padrão), essas operações retornarão automaticamente os novos valores após atualizar os valores atuais da `Variable`. Definir o `read_value` como `False` suprimirá o retorno automático do valor atualizado (mas a `Variable` ainda será atualizada no local). Chamar `w.value()` retornará os valores em um formato de tensor. Observe que não podemos alterar a forma ou o tipo da `Variable` durante a atribuição.\n",
    "\n",
    "Você deve se lembrar de que, para modelos de Rede Neural, é necessário inicializar os parâmetros do modelo com pesos aleatórios para quebrar a simetria durante a retropropagação - caso contrário, uma RN multicamada não seria mais útil do que uma RN de camada única, como regressão logística. Ao criar uma variável do *TensorFlow*, também podemos usar um esquema de inicialização aleatório. O *TensorFlow* pode gerar números aleatórios com base em várias distribuições via `tf.random`.\n",
    "\n",
    "No exemplo a seguir, veremos alguns métodos de inicialização padrão que também estão disponíveis no *Keras*. Então, vamos ver como podemos criar uma `Variable` com inicialização *Glorot*, que é um esquema clássico de inicialização aleatória que foi proposto por Xavier Glorot e Yoshua Bengio. Para isso, criamos um operador chamado `init` como objeto da classe `GlorotNormal`. Então, chamamos esse operador e fornecemos a forma desejada do tensor de saída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.722795904 1.01456821 0.251808226]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "tf.print(init(shape=(3,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos usar este operador para inicializar uma `Variable` de formato 2 × 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28982234 -0.782292783 -0.0453658961]\n",
      " [0.960991383 -0.120003454 0.708528221]]\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(init(shape=(2, 3)))\n",
    "tf.print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, para colocar isso no contexto de um caso de uso mais prático, vamos ver como podemos definir uma `Variable` dentro da classe base `tf.Module`. Vamos definir duas variáveis: uma treinável e uma não treinável:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All module variables: [TensorShape([2, 3]), TensorShape([1, 2])]\n",
      "Trainable variable:   [TensorShape([2, 3])]\n"
     ]
    }
   ],
   "source": [
    "class MyModule (tf.Module):\n",
    "    def __init__(self):\n",
    "        init = tf.keras.initializers.GlorotNormal()\n",
    "        self.w1 = tf.Variable(init(shape=(2,3)),\n",
    "                                    trainable=True)\n",
    "        self.w2 = tf.Variable(init(shape=(1,2)),\n",
    "                                trainable = False)\n",
    "\n",
    "m = MyModule()\n",
    "\n",
    "print('All module variables:', [v.shape for v in m.variables])\n",
    "\n",
    "print('Trainable variable:  ', [v.shape for v in m.trainable_variables])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode ver neste exemplo de código, a subclasse da classe `tf.Module` nos dá acesso direto a todas as variáveis definidas em um determinado objeto (aqui, uma instância de nossa classe `MyModule` personalizada) por meio do atributo `.variables`.\n",
    "\n",
    "Finalmente, vamos ver como usar variáveis dentro de uma função decorada com `tf.function`. Quando definimos uma `Variable` do TensorFlow dentro de uma função normal (não decorada), podemos esperar que uma nova `Variable` seja criada e inicializada toda vez que a função for chamada. No entanto, `tf.function` tentará reutilizar a `Variable` com base no rastreamento e na criação do gráfico. Portanto, o *TensorFlow* não permite a criação de uma `Variable` dentro de uma função decorada e, como resultado, o código a seguir gerará um erro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\willi\\AppData\\Local\\Temp/ipykernel_11580/3931184721.py\", line 3, in f  *\n        w = tf.Variable([1,2,3])\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11580/3931184721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\willi\\AppData\\Local\\Temp/ipykernel_11580/3931184721.py\", line 3, in f  *\n        w = tf.Variable([1,2,3])\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    w = tf.Variable([1,2,3])\n",
    "\n",
    "f([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma maneira de evitar esse problema é definir a variável fora da função decorada e usá-la dentro da função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.20935762]\n",
      " [3.89828062]\n",
      " [1.65398622]]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random.uniform((3, 3)))\n",
    "\n",
    "@ tf.function\n",
    "def compute_z(x):\n",
    "    return tf.matmul(w , x)\n",
    "\n",
    "x = tf.constant([[1], [2], [3]], dtype=tf.float32)\n",
    "\n",
    "tf.print(compute_z(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computação de gradientes via diferenciação automática e *GradientTape*\n",
    "\n",
    "Como você já sabe, otimizar RNs requer calcular os gradientes do custo em relação aos pesos da Rn. Isso é necessário para algoritmos de otimização, como gradiente descendente estocástico (SGD). Além disso, os gradientes têm outras aplicações, como diagnosticar a rede para descobrir por que um modelo de RN está fazendo uma previsão específica para um exemplo de teste. Portanto, nesta seção, abordaremos como calcular gradientes de uma computação em relação a algumas variáveis.\n",
    "\n",
    "### Calculando os gradientes da perda em relação às variáveis ​​treináveis\n",
    "\n",
    "O *TensorFlow* oferece suporte à **diferenciação automática**, que pode ser considerada uma implementação da regra da cadeia para calcular gradientes de funções aninhadas. Quando definimos uma série de operações que resultam em alguma saída ou mesmo tensores intermediários, o *TensorFlow* fornece um contexto para calcular gradientes desses tensores calculados em relação a seus nós dependentes no gráfico de computação. Para calcular esses gradientes, temos que \"gravar\" os cálculos via `tf.GradientTape`.\n",
    "\n",
    "Vamos trabalhar com um exemplo simples onde vamos calcular $\\small z = wx + b$ e definir a perda como a perda ao quadrado entre o alvo e a previsão, $\\small Loss = (y - z)^2$. No caso mais geral, onde podemos ter várias previsões e metas, calcule a perda como a soma do erro ao quadrado, $\\small Loss = \\sum_i(y_i - z_i)^2$. Para implementar esse cálculo no *TensorFlow*, vamos definir os parâmetros do modelo, $\\small w$ e $\\small b$, como variáveis, e as entradas $\\small x$ e $\\small y$, como tensores. Colocaremos o cálculo de $\\small z$ e a perda dentro do contexto `tf.GradientTape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w = tf.Variable(1.0)\n",
    "b = tf.Variable(0.5)\n",
    "print(w.trainable, b.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw :  -0.559999764\n"
     ]
    }
   ],
   "source": [
    "x = tf.convert_to_tensor([1.4])\n",
    "y = tf.convert_to_tensor([2.1])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tf.add(tf.multiply(w, x), b)\n",
    "    loss = tf.reduce_sum(tf.square(y - z))\n",
    "\n",
    "dloss_dw = tape.gradient(loss, w)\n",
    "\n",
    "tf.print('dL/dw : ', dloss_dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao calcular o valor $\\small z$, podemos pensar nas operações necessárias, que gravamos na \"gradient tape\", como uma passagem para frente em uma RN. Usamos `tape.gradient` para calcular $\\small \\dfrac{\\partial Loss}{\\partial w}$ . Como este é um exemplo muito simples, podemos obter as derivadas, $\\small \\dfrac {\\partial Loss}{\\partial w} = 2x(wx + b - y)$, simbolicamente para verificar que os gradientes calculados obtivemos no exemplo de código anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.559999764]\n"
     ]
    }
   ],
   "source": [
    "# verifying the computed gradient\n",
    "tf.print(2*x*(w*x  + b - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computação de gradientes em relação a tensores não treináveis\n",
    "\n",
    "`tf.GradientTape` suporta automaticamente os gradientes para variáveis treináveis. No entanto, para variáveis não treináveis e outros objetos `Tensor`, precisamos adicionar uma modificação adicional ao `GradientTape` chamada `tape.watch()` para monitorá-los também. Por exemplo, se estivermos interessados em calcular $\\small \\dfrac {\\partial Loss}{\\partial x}$ , o código será o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dx: [-0.399999857]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    z = tf.add(tf.multiply(w, x), b)\n",
    "    loss = tf.square(y - z)\n",
    "\n",
    "dloss_dx = tape.gradient(loss, x)\n",
    "\n",
    "tf.print('dL/dx:', dloss_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.399999857]\n"
     ]
    }
   ],
   "source": [
    "# verifying the computed gradient\n",
    "tf.print(2*w * ((w*x + b) - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mantendo recursos para vários cálculos de gradiente\n",
    "Quando monitoramos os cálculos no contexto de`tf.GradientTape`, por padrão, a fita manterá os recursos apenas para um único cálculo de gradiente. Por exemplo, após chamar `tape.gradient()` uma vez, os recursos serão liberados e a fita será limpa. Portanto, se quisermos calcular mais de um gradiente, por exemplo, ambos $\\small \\dfrac {\\partial Loss}{\\partial w}$ e $\\small \\dfrac {\\partial Loss}{\\partial b}$ , precisamos tornar a fita persistente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw: -0.559999764\n",
      "dL/db: -0.399999857\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = tf.add(tf.multiply(w, x), b)\n",
    "    loss = tf.reduce_sum(tf.square(y - z))\n",
    "\n",
    "dloss_dw = tape.gradient(loss, w)\n",
    "dloss_db = tape.gradient(loss, b)\n",
    "\n",
    "tf.print('dL/dw:', dloss_dw)\n",
    "tf.print('dL/db:', dloss_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.559999764]\n"
     ]
    }
   ],
   "source": [
    "tf.print(2*x * ((w*x + b) - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, lembre-se de que isso só é necessário quando queremos calcular mais de um gradiente, pois gravar e manter a fita gradiente é menos eficiente em termos de memória em comparação com liberar a memória após um único cálculo de gradiente. É também por isso que a configuração padrão é `persistent=False`.\n",
    "\n",
    "Finalmente, se estivermos computando gradientes de um termo de perda em relação aos parâmetros de um modelo, podemos definir um otimizador e aplicar os gradientes para otimizar os parâmetros do modelo usando a API `tf.keras`, como segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11580/1668671848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdloss_dw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdloss_db\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Updated w:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\willi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    666\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_unaggregated_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aggregate_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\willi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_aggregate_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m    482\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_aggregator\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \"\"\"\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_aggregator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_transform_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\willi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\utils.py\u001b[0m in \u001b[0;36mall_reduce_sum_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     31\u001b[0m   \u001b[0mfiltered_grads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_empty_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mfiltered_grads_and_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltered_grads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m       reduced = tf.distribute.get_replica_context().all_reduce(\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD()\n",
    "\n",
    "optimizer.apply_gradients(zip([dloss_dw, dloss_db], [w, b]))\n",
    "\n",
    "tf.print('Updated w:', w)\n",
    "tf.print('Updated bias:', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c198a0bf143da720db8a1ed2fdc43342371f98b364fdf2ef3c0c72d17a471d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
