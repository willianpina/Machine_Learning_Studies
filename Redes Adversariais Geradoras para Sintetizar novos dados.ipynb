{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>Redes Adversariais Geradoras para Sintetizar Novos Dados</h1>\n",
    "\n",
    "<p align=center><img src=https://advancedinstitute.ai/wp-content/uploads/2020/08/real_fake.png width=500></p>\n",
    "\n",
    "Anteriomente, focamos em redes neurais recorrentes (RNN) para modelagem de sequ√™ncias. Aqui, exploraremos as redes generativas de advers√°rios (GANs) e veremos sua aplica√ß√£o na s√≠ntese de novas amostras de dados. As GANs s√£o consideradas o avan√ßo mais importante no aprendizado profundo, permitindo que os computadores gerem novos dados (como novas imagens).\n",
    "\n",
    "Aqui, abordaremos os seguintes t√≥picos:\n",
    "* Apresentando modelos generativos para sintetizar novos dados\n",
    "* Autoencoders, autoencoders variacionais (VAEs) e seu relacionamento com GANs\n",
    "* Entendendo os blocos de constru√ß√£o das GANs\n",
    "* Implementa√ß√£o de um modelo GAN simples para gerar d√≠gitos manuscritos\n",
    "* No√ß√µes b√°sicas sobre convolu√ß√£o transposta e normaliza√ß√£o de lote (BatchNorm ou BN)\n",
    "* Melhorar GANs: GANs convolucionais profundos e GANs usando a dist√¢ncia de Wasserstein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apresentando redes advers√°rias generativas\n",
    "Vamos primeiro olhar para os fundamentos dos modelos GAN. O objetivo geral de uma GAN √© <u>sintetizar novos dados que tenham a mesma distribui√ß√£o que seu conjunto de dados de treinamento</u>. Portanto, as GANs, em sua forma original, s√£o consideradas na categoria de aprendizado n√£o supervisionado de tarefas de aprendizado de m√°quina, pois n√£o s√£o necess√°rios dados rotulados. Vale a pena notar, no entanto, que as extens√µes feitas ao GAN original podem estar em tarefas semi-supervisionadas e supervisionadas.\n",
    "\n",
    "O conceito geral de GAN foi proposto pela primeira vez em 2014 por Ian Goodfellow e seus colegas como um m√©todo para sintetizar novas imagens usando redes neurais profundas (NNs). Embora a arquitetura GAN inicial proposta fosse baseada em camadas totalmente conectadas, semelhantes √†s arquiteturas *perceptron* multicamadas, e treinadas para gerar d√≠gitos manuscritos de baixa resolu√ß√£o do tipo MNIST, ela serviu mais como uma prova de conceito para demonstrar a viabilidade dessa nova abordagem.\n",
    "\n",
    "No entanto, desde sua introdu√ß√£o, os autores originais, assim como muitos outros pesquisadores, propuseram in√∫meras melhorias e diversas aplica√ß√µes em diferentes campos da engenharia e da ci√™ncia; por exemplo, em vis√£o computacional, GANs s√£o usadas ‚Äã‚Äãpara tradu√ß√£o de imagem para imagem (aprender a mapear uma imagem de entrada para uma imagem de sa√≠da), super-resolu√ß√£o de imagem (criar uma imagem de alta resolu√ß√£o a partir de uma vers√£o de baixa resolu√ß√£o), pintura interna de imagem (aprender a reconstruir as partes que faltam de uma imagem) e muitas outras aplica√ß√µes. Por exemplo, os avan√ßos recentes na pesquisa de GAN levaram a modelos capazes de gerar novas imagens de rosto de alta resolu√ß√£o. Exemplos dessas imagens de alta resolu√ß√£o podem ser encontrados em https://www.thispersondoesnotexist.com/, que mostra imagens de rosto sint√©ticas geradas por uma GAN.\n",
    "\n",
    "### Come√ßando com os *autoencoders*\n",
    "Antes de discutirmos como as GANs funcionam, come√ßaremos com os *autoencoders*, que podem compactar e descompactar dados de treinamento. Embora os codificadores autom√°ticos padr√£o n√£o possam gerar novos dados, entender sua fun√ß√£o ajudar√° voc√™ a navegar pelas GANs na pr√≥xima se√ß√£o.\n",
    "\n",
    "Autoencoders s√£o compostos por duas redes concatenadas: uma rede codificadora e uma rede decodificadora. A rede codificadora recebe um vetor de recurso de entrada *d*-dimensional associado ao exemplo **x** (ou seja, ***x*** $\\small \\in R^p$) e o codifica em um vetor *p*-dimensional, `z` (ou seja, ***z*** $\\small \\in R^p$). Em outras palavras, o papel do codificador √© aprender a modelar a fun√ß√£o ***z*** = $\\small f(x)$ . O vetor codificado, `z`, tamb√©m √© chamado de vetor latente ou representa√ß√£o de caracter√≠stica latente. Normalmente, a dimensionalidade do vetor latente √© menor que a dos exemplos de entrada; em outras palavras, $\\small p < d$. Assim, podemos dizer que o codificador atua como uma fun√ß√£o de compress√£o de dados. Ent√£o, o decodificador descomprime $\\small \\hat{x}$ do vetor latente de menor dimens√£o, `z`, onde podemos pensar no decodificador como uma fun√ß√£o, $\\small \\hat{x} = g(z)$. Uma arquitetura simples de *autoencoder* √© mostrada na figura a seguir, onde as partes do codificador e do decodificador consistem em apenas uma camada totalmente conectada cada:\n",
    "\n",
    "![](imagens\\autoencoder.PNG)\n",
    "\n",
    "> ##### A conex√£o entre autoencoders e redu√ß√£o de dimensionalidade\n",
    "> Certamente voc√™ j√° aprendeu sobre t√©cnicas de redu√ß√£o de dimensionalidade, como an√°lise de componentes principais (PCA) e an√°lise discriminante linear (LDA). *Autoencoders* tamb√©m podem ser usados como uma **t√©cnica de redu√ß√£o de dimensionalidade**. De fato, quando n√£o h√° n√£o linearidade em nenhuma das duas sub-redes (codificador e decodificador), a abordagem do autoencoder √© quase id√™ntica ao PCA.\n",
    ">\n",
    "> Nesse caso, se assumirmos que os pesos de um codificador de camada √∫nica (sem camada oculta e sem fun√ß√£o de ativa√ß√£o n√£o linear) s√£o denotados pela matriz **U**, ent√£o os modelos do codificador **z** = $\\small U^Tx$. Da mesma forma, um decodificador linear de camada √∫nica modela $\\small \\hat{x} = Uz$. Juntando esses dois componentes, temos $\\small \\hat{x} = UU^Tx$. Isso √© exatamente o que o PCA faz, com a exce√ß√£o de que o PCA tem uma restri√ß√£o ortonormal adicional: $\\small UU^T = I_{n \\times n}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora a figura anterior represente um *autoencoder* sem camadas ocultas dentro do codificador e do decodificador, podemos, √© claro, adicionar v√°rias camadas ocultas com n√£o linearidades (como em uma NN multicamada) para construir um *autoencoder* profundo que pode aprender fun√ß√µes de reconstru√ß√£o e compacta√ß√£o de dados mais eficazes. Al√©m disso, observe que o *autoencoder* mencionado nesta se√ß√£o usa camadas totalmente conectadas. Quando trabalhamos com imagens, no entanto, podemos substituir as camadas totalmente conectadas por camadas convolucionais.\n",
    "\n",
    "> ##### Outros tipos de autoencoders baseados no tamanho do espa√ßo latente\n",
    "> Como mencionado anteriormente, a dimensionalidade do espa√ßo latente de um *autoencoder* √© tipicamente menor que a dimensionalidade das entradas ($\\small p < d$), o que torna os autoencoders adequados para redu√ß√£o de dimensionalidade. Por esse motivo, o vetor latente tamb√©m √© frequentemente chamado de \"gargalo\", e essa configura√ß√£o espec√≠fica de um *autoencoder* tamb√©m √© chamada de `undercomplete` (subcompleto). No entanto, existe uma categoria diferente de *autoencoders*, chamada `overcomplete`, onde a dimensionalidade do vetor latente, `z`, √©, de fato, maior que a dimensionalidade dos exemplos de entrada ($\\small p > d$).\n",
    "\n",
    "Ao treinar um *autoencoder* `overcomplete` (supercompleto), h√° uma solu√ß√£o trivial em que o codificador e o decodificador podem simplesmente aprender a copiar (memorizar) os recursos de entrada para sua camada de sa√≠da. Obviamente, esta solu√ß√£o n√£o √© muito √∫til. No entanto, com algumas modifica√ß√µes no procedimento de treinamento, os *autoencoders* supercompletos podem ser usados **‚Äã‚Äãpara redu√ß√£o de ru√≠do**. Nesse caso, durante o treinamento, o ru√≠do aleat√≥rio, $\\epsilon$, √© adicionado aos exemplos de entrada e a rede aprende a reconstruir o exemplo, `x`, do sinal ruidoso, $\\small x + \\epsilon$. Ent√£o, no momento da avalia√ß√£o, fornecemos os novos exemplos que s√£o naturalmente ruidosos (ou seja, o ru√≠do j√° est√° presente de modo que nenhum ru√≠do artificial adicional, $\\epsilon$, √© adicionado) para remover o ru√≠do existente desses exemplos. Essa arquitetura de *autoencoder* e o m√©todo de treinamento espec√≠ficos s√£o chamados de *autoencoder* de redu√ß√£o de ru√≠do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos generativos para sintetizar novos dados\n",
    "\n",
    "Autoencoders s√£o modelos determin√≠sticos, o que significa que depois que um autoencoder √© treinado, dada uma entrada, **x**, ele ser√° capaz de reconstruir a entrada de sua vers√£o compactada em um espa√ßo de menor dimens√£o. Portanto, ele n√£o pode gerar novos dados al√©m de reconstruir sua entrada por meio da transforma√ß√£o da representa√ß√£o compactada.\n",
    "\n",
    "Um modelo generativo, por outro lado, pode gerar um novo exemplo, $\\small \\tilde{x}$ , a partir de um vetor aleat√≥rio, **z** (correspondente √† representa√ß√£o latente). Uma representa√ß√£o esquem√°tica de um modelo generativo √© mostrada na figura a seguir. O vetor aleat√≥rio, **z**, vem de uma distribui√ß√£o simples com caracter√≠sticas totalmente conhecidas, ent√£o podemos facilmente amostrar de tal distribui√ß√£o. Por exemplo, cada elemento de **z** pode vir da distribui√ß√£o uniforme no intervalo [‚Äì1, 1] (para a qual escrevemos $\\small z_i \\sim \\: Uniform(-1,1)$ ou de uma distribui√ß√£o normal padr√£o (nesse caso, escrevemos $\\small z_i \\sim \\: Normal (\\mu = 0, \\sigma^2=1)$).\n",
    "\n",
    "<p><img src =imagens\\generative_model.PNG></p>\n",
    "\n",
    "\n",
    "√Ä medida que mudamos nossa aten√ß√£o de autoencoders para modelos generativos, voc√™ deve ter notado que o componente decodificador de um *autoencoder* tem algumas semelhan√ßas com um modelo generativo. Em particular, ambos recebem um vetor latente, **z**, como entrada e retornam uma sa√≠da no mesmo espa√ßo que **x**. (Para o *autoencoder*, $\\small \\hat{x}$ √© a reconstru√ß√£o de uma entrada, **x**, e para o modelo generativo, $\\small \\tilde{x}$ √© uma amostra sintetizada.)\n",
    "\n",
    "No entanto, a principal diferen√ßa entre os dois √© que n√£o conhecemos a distribui√ß√£o de **z** no *autoencoder*, enquanto em um modelo generativo, a distribui√ß√£o de **z** √© totalmente caracteriz√°vel. No entanto, √© poss√≠vel generalizar um *autoencoder* em um modelo generativo. Uma abordagem s√£o os **VAEs**. Em um VAE que recebe um exemplo de entrada, **x**, a rede do codificador √© modificada de tal forma que computa dois momentos da distribui√ß√£o do vetor latente: a m√©dia, $\\small \\mu$, e a vari√¢ncia, $\\small \\sigma^2$. Durante o treinamento de um VAE, a rede √© for√ßada a combinar esses momentos com os de uma distribui√ß√£o normal padr√£o (ou seja, **m√©dia zero e vari√¢ncia unit√°ria**). Ent√£o, depois que o modelo VAE √© treinado, o codificador √© descartado e podemos usar a rede do decodificador para gerar novos exemplos, $\\small \\tilde{x}$, alimentando vetores **z** aleat√≥rios da distribui√ß√£o gaussiana \"aprendida\". Al√©m dos VAEs, existem outros tipos de modelos generativos, por exemplo, modelos autorregressivos e modelos de fluxo normalizador. No entanto, vamos nos concentrar apenas nos modelos GAN, que est√£o entre os tipos mais recentes e populares de modelos generativos em deep learning.\n",
    "\n",
    "\n",
    "> ##### O que √© um modelo generativo?\n",
    "> Observe que os modelos generativos s√£o tradicionalmente definidos como algoritmos que modelam as distribui√ß√µes de entrada de dados, $\\small p(x)$, ou as distribui√ß√µes conjuntas dos dados de entrada e alvos associados, $\\small p(x, y)$. Por defini√ß√£o, esses modelos tamb√©m s√£o capazes de amostrar de algum recurso, $\\small x_i$, condicionado a outro recurso, $\\small x_j$, conhecido como **infer√™ncia condicional**. No contexto de aprendizado profundo, no entanto, o termo **modelo generativo** √© normalmente usado para se referir a modelos que geram dados de apar√™ncia realista. Isso significa que podemos amostrar a partir de distribui√ß√µes de entrada, $\\small p(x)$, mas n√£o somos necessariamente capazes de realizar infer√™ncia condicional.\n",
    "\n",
    "### Gerando novas amostras com GANs\n",
    "Para entender o que as GANs fazem em poucas palavras, vamos primeiro supor que temos uma rede que recebe um vetor aleat√≥rio, **z**, amostrado de uma distribui√ß√£o conhecida e gera uma imagem de sa√≠da, **x**. Chamaremos esse **gerador de rede** (G) e usaremos a nota√ß√£o $\\small \\tilde{x} = G(z)$ para nos referirmos √† sa√≠da gerada. Suponha que nosso objetivo seja gerar algumas imagens, por exemplo, imagens de rostos, imagens de pr√©dios, imagens de animais ou at√© mesmo d√≠gitos manuscritos como o MNIST.\n",
    "\n",
    "Como sempre, inicializaremos essa rede com pesos aleat√≥rios. Portanto, as primeiras imagens de sa√≠da, antes que esses pesos sejam ajustados, parecer√£o ru√≠do branco. Agora, imagine que existe uma fun√ß√£o que pode avaliar a qualidade das imagens (vamos cham√°-la de **fun√ß√£o avaliadora**).\n",
    "\n",
    "Se tal fun√ß√£o existir, podemos usar o feedback dessa fun√ß√£o para informar √† nossa rede geradora como ajustar seus pesos para melhorar a qualidade das imagens geradas. Dessa forma, podemos treinar o gerador com base no feedback dessa fun√ß√£o avaliadora, de modo que o gerador aprenda a melhorar sua sa√≠da para produzir imagens de apar√™ncia realista.\n",
    "\n",
    "Enquanto uma fun√ß√£o de avaliador, conforme descrito no par√°grafo anterior, facilitaria muito a tarefa de gera√ß√£o de imagens, a quest√£o √© se existe uma fun√ß√£o t√£o universal para avaliar a qualidade das imagens e, em caso afirmativo, como ela √© definida. Obviamente, como humanos, podemos facilmente avaliar a qualidade das imagens de sa√≠da quando observamos as sa√≠das da rede; embora n√£o possamos (ainda) retropropagar o resultado do nosso c√©rebro para a rede. Agora, se nosso c√©rebro pode avaliar a qualidade das imagens sintetizadas, podemos projetar um modelo NN para fazer a mesma coisa? Na verdade, essa √© a ideia geral de uma GAN. Conforme mostrado na figura a seguir, um modelo GAN consiste em uma NN adicional chamado **discriminador** (D), que √© um classificador que aprende a detectar uma imagem sintetizada, $\\small \\tilde{x}$, a partir de uma imagem real, **x**:\n",
    "\n",
    "<p><img src = imagens\\gerador_discriminador.PNG></p>\n",
    "\n",
    "Em um modelo GAN, as duas redes, geradora e discriminadora, s√£o treinadas juntas. A princ√≠pio, ap√≥s inicializar os pesos do modelo, o gerador cria imagens que n√£o parecem realistas. Da mesma forma, o discriminador faz um trabalho ruim ao distinguir entre imagens reais e imagens sintetizadas pelo gerador. Mas com o tempo (ou seja, por meio de treinamento), ambas as redes se tornam melhores √† medida que interagem entre si. De fato, as duas redes fazem um jogo de advers√°rios, onde o gerador aprende a melhorar sua sa√≠da para poder enganar o discriminador. Ao mesmo tempo, o discriminador se torna melhor na detec√ß√£o das imagens sintetizadas.\n",
    "\n",
    "\n",
    "\n",
    "### Entendendo as fun√ß√µes de perda das redes geradoras e discriminadoras em um modelo GAN\n",
    "A fun√ß√£o objetivo das GANs, conforme descrito no artigo original Generative Adversarial Nets de Goodfellow et al. (https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), √© o seguinte:\n",
    "\n",
    "$$\n",
    "\\small V\\left ( \\theta ^{D}, \\theta^{(G)} \\right ) = E_{x \\sim p_{data}(x))}[logD(x)] + E_{z\\sim p_z(z))}\\left [ log(1-D(G(z))) \\right ]\n",
    "$$\n",
    "\n",
    "Aqui, $\\small V\\left ( \\theta ^{D}, \\theta^{(G)} \\right )$ √© chamada de *fun√ß√£o valor*, que pode ser interpretada como uma recompensa: queremos maximizar seu valor em rela√ß√£o ao discriminador (D), enquanto minimizamos seu valor em rela√ß√£o a o gerador (G), ou seja, min $\\small \\underset{G}{min} \\: \\underset{D}{max} \\: V(\\theta^{(D)}, \\theta^{(G)})$.\n",
    "$D_{(x)}$ √© a probabilidade que indica se o exemplo de entrada, **x**, √© real ou falso (ou seja, gerado). A express√£o $\\small E_{x \\sim p_{data}(x))}[logD(x)]$ refere-se ao valor esperado da quantidade entre par√™nteses em rela√ß√£o aos exemplos da distribui√ß√£o de dados (distribui√ß√£o dos exemplos reais); $\\small E_{z\\sim p_z(z))}\\left [ log(1-D(G(z))) \\right]$ refere-se ao valor esperado da quantidade em rela√ß√£o √† distribui√ß√£o dos vetores de entrada, **z**.\n",
    "\n",
    "Uma etapa de treinamento de um modelo GAN com tal fun√ß√£o de valor requer duas etapas de otimiza√ß√£o: (1) maximizar o retorno para o discriminador e (2) minimizar o retorno para o gerador. Uma maneira pr√°tica de treinar GANs √© alternar entre essas duas etapas de otimiza√ß√£o: (1) corrigir (congelar) os par√¢metros de uma rede e otimizar os pesos da outra e (2) corrigir a segunda rede e otimizar a primeira. Este processo deve ser repetido a cada itera√ß√£o de treinamento. Vamos supor que a rede geradora seja fixa e queremos otimizar o discriminador. Ambos os termos da fun√ß√£o valor $\\small V\\left ( \\theta ^{D}, \\theta^{(G)} \\right )$ contribuem para otimizar o discriminador, onde o primeiro termo corresponde √† perda associada aos exemplos reais, e o segundo termo √© a perda aos exemplos falsos. Portanto, quando G √© fixo, nosso objetivo √© *maximizar* $\\small V\\left ( \\theta ^{D}, \\theta^{(G)} \\right )$, o que significa tornar o discriminador melhor na distin√ß√£o entre imagens reais e geradas.\n",
    "\n",
    "\n",
    "Depois de otimizar o discriminador usando os termos de perda para amostras reais e falsas, corrigimos o discriminador e otimizamos o gerador. Neste caso, apenas o segundo termo em $\\small V\\left ( \\theta ^{D}, \\theta^{(G)} \\right )$ contribui para os gradientes do gerador. Como resultado, quando *D* √© fixo, nosso objetivo √© *minimizar* $\\small V\\left ( \\theta ^{D}, \\theta^{(G)} \\right )$ , que pode ser escrito como $\\small \\underset{G}{min}\\:E_{z\\sim p_z(z))}\\left [ log(1-D(G(z))) \\right]$. Como foi mencionado no artigo GAN original de Goodfellow et al., esta fun√ß√£o, $\\small log(1-D(G(z)))$, sofre de gradientes de fuga nos est√°gios iniciais de treinamento. A raz√£o para isso √© que as sa√≠das, $\\small G_{(z)}$, no in√≠cio do processo de aprendizagem, n√£o se parecem em nada com exemplos reais e, portanto, $\\small D(G_{(z)})$ ser√° pr√≥ximo de zero com alta confian√ßa. Esse fen√¥meno √© chamado de **satura√ß√£o**. Para resolver esse problema, podemos reformular o objetivo de minimiza√ß√£o, $\\small\\underset{G}{min}\\:E_{z\\sim p_z(z))}\\left [ log(1-D(G(z))) \\right ]$,\n",
    "reescrevendo-o como $\\small \\underset{G}{max}\\:E_{z\\sim p_z(z))}\\left [ log(D(G(z))) \\right ]$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Essa substitui√ß√£o significa que para treinar o gerador, podemos trocar os r√≥tulos de exemplos reais e falsos e realizar uma minimiza√ß√£o regular da fun√ß√£o. Em outras palavras, mesmo que os exemplos sintetizados pelo gerador sejam falsos e, portanto, rotulados como 0, podemos inverter os r√≥tulos atribuindo o r√≥tulo 1 a esses exemplos e minimizar a perda de entropia cruzada bin√°ria com esses novos r√≥tulos em vez de maximizar max ùê∫ùê∫\n",
    "ùê∏ùê∏ùíõùíõ‚àºùëùùëùùíõùíõ(ùíõùíõ) [log (ùê∑ùê∑(ùê∫ùê∫(ùíõùíõ)))] . Agora que abordamos o procedimento geral de otimiza√ß√£o para treinar modelos de GAN, vamos explorar os v√°rios r√≥tulos de dados que podemos usar ao treinar GANs.\n",
    "Dado que o discriminador √© um classificador bin√°rio (os r√≥tulos de classe s√£o 0 e 1 para imagens falsas e reais, respectivamente), podemos usar a fun√ß√£o de perda de entropia cruzada bin√°ria. Portanto, podemos determinar os r√≥tulos de verdade do terreno para a perda do discriminador da seguinte forma:\n",
    "R√≥tulos de verdade\n",
    "para o discriminador = {1:\n",
    "para imagens reais, i. e. , ùíôùíô\n",
    "0:\n",
    "para sa√≠das de ùê∫ùê∫, i. e. , ùê∫ùê∫(ùíõùíõ)\n",
    "E as etiquetas para treinar o gerador? Como queremos que o gerador sintetize imagens realistas, queremos penalizar o gerador quando suas sa√≠das n√£o forem classificadas como reais pelo discriminador. Isso significa que assumiremos os r√≥tulos de verdade do terreno para as sa√≠das do gerador como 1 ao calcular a fun√ß√£o de perda para o gerador."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c198a0bf143da720db8a1ed2fdc43342371f98b364fdf2ef3c0c72d17a471d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
